{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "green-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from datasets import Split_Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('/gpfs/u/locker/200/CADS/datasets/ImageNet/val', transform=val_transforms)\n",
    "\n",
    "val_dataset = Split_Dataset('/gpfs/u/locker/200/CADS/datasets/ImageNet',  \\\n",
    "                    f'./calib_splits/am_imagenet_5percent_val.txt',\n",
    "                    transform=val_transforms)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=True,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loved-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(test_dataset))\n",
    "test_dataset = Subset(test_dataset, list(indices))\n",
    "\n",
    "subset_test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vulnerable-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: /gpfs/u/locker/200/CADS/datasets/ImageNet/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(subset_test_loader.dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "toxic-conversion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_test_loader.dataset.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-superintendent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hindu-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "split_idx_path = './misc/imagenet_train_val_split.pth'\n",
    "if os.path.exists(split_idx_path):\n",
    "    split_idx = torch.load(split_idx_path)\n",
    "else:\n",
    "    raise Exception('Imagenet train-val split dict file does not exist! git pull ')\n",
    "test_dataset = Subset(test_dataset, split_idx[0]['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "proud-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "streaming-funeral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: /gpfs/u/locker/200/CADS/datasets/ImageNet/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.dataset.dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "imposed-demand",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "completed-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensem_pred(outputs, mode='DE', num_ensem=3, target=None):\n",
    "    output = outputs.softmax(dim=-1).mean(dim=0)\n",
    "    _, ensem_preds = output.max(1)\n",
    "    batch_acc = (ensem_preds.long() == target).sum()/ len(target)\n",
    "    conf, preds = outputs.max(dim=-1) # each has dim (M,B)\n",
    "    pred_exist = (preds == target).sum(dim=0).bool()\n",
    "    acc_ub = 1 - (~pred_exist).sum()/len(pred_exist)\n",
    "\n",
    "    return ensem_preds, target, output, acc_ub * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "official-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.resnet50().cuda()\n",
    "model2 = models.resnet50().cuda()\n",
    "model3 = models.resnet50().cuda()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_baseR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model1.load_state_dict(ckpt)\n",
    "model1.eval()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_eqR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model2.load_state_dict(ckpt)\n",
    "model2.eval()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_inv_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model3.load_state_dict(ckpt)\n",
    "model3.eval()\n",
    "\n",
    "gate = models.resnet18(num_classes=3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parallel-resort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8626, device='cuda:0') tensor(0.8148, device='cuda:0')\n",
      "251 torch.Size([256, 3]) torch.Size([102, 3])\n",
      "torch.Size([64102, 3])\n",
      "tensor(45806, device='cuda:0')\n",
      "tensor(5462, device='cuda:0')\n",
      "tensor(4024, device='cuda:0')\n",
      "tensor(8810, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w_acc = 0\n",
    "n_acc = 0\n",
    "\n",
    "targets = []\n",
    "for it, (img,target) in enumerate(val_loader):\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        output1 = model1(img)\n",
    "        output2 = model2(img)\n",
    "        output3 = model3(img)\n",
    "        preds = torch.stack([output1,output2,output3])\n",
    "        _, all_preds = preds.max(-1)\n",
    "        label_matrix = (all_preds == target).float().T\n",
    "        logit = label_matrix.T.unsqueeze(2).repeat(1,1,1000) * preds.softmax(dim=-1)\n",
    "        weighted_ensem = logit.sum(dim=0)\n",
    "        naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "        _, w_ensem_pred = weighted_ensem.max(-1)\n",
    "        _, n_ensem_pred = naive_ensem.max(-1)\n",
    "        w_acc += (w_ensem_pred == target).sum()\n",
    "        n_acc += (n_ensem_pred == target).sum()\n",
    "#     print(w_acc, n_acc)\n",
    "    targets.append(label_matrix)\n",
    "    \n",
    "print(w_acc/len(val_dataset), n_acc/len(val_dataset))\n",
    "print(len(targets), targets[0].shape, targets[-1].shape)\n",
    "all_targets = torch.cat(targets)\n",
    "print(all_targets.shape)\n",
    "num_correct = all_targets.sum(-1)\n",
    "print((num_correct == 3).sum())\n",
    "print((num_correct == 2).sum())\n",
    "print((num_correct == 1).sum())\n",
    "print((num_correct == 0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fitting-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-magnitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7145798883030171\n",
      "0.08520794982995851\n",
      "0.0627749524195813\n",
      "0.13743720944744314\n",
      "tensor(9486, device='cuda:0') 64102\n"
     ]
    }
   ],
   "source": [
    "print(45806/64102)\n",
    "print(5462/64102)\n",
    "print(4024/64102)\n",
    "print(8810/64102)\n",
    "\n",
    "mask = (num_correct == 2) | (num_correct == 1)\n",
    "print(mask.sum(), len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signed-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   77    78    96 ... 64089 64090 64096]\n",
      "[49883 60066 53164 ...  2996 45079  4174]\n"
     ]
    }
   ],
   "source": [
    "indices = torch.where(mask == True)[0].cpu().numpy()\n",
    "print(indices)\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "val_ds = Split_Dataset('/gpfs/u/locker/200/CADS/datasets/ImageNet',  \\\n",
    "                    f'./calib_splits/am_imagenet_5percent_val.txt',\n",
    "                    transform=val_transforms)\n",
    "subset_val = Subset(val_ds, list(indices))\n",
    "\n",
    "subset_val_loader = torch.utils.data.DataLoader(\n",
    "            subset_val, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "senior-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1480, device='cuda:0') tensor(0.0998, device='cuda:0')\n",
      "38 torch.Size([256, 3]) torch.Size([14, 3])\n",
      "torch.Size([9486, 3])\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(5462, device='cuda:0')\n",
      "tensor(4024, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w_acc = 0\n",
    "n_acc = 0\n",
    "\n",
    "targets = []\n",
    "for it, (img, target) in enumerate(subset_val_loader):\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        output1 = model1(img)\n",
    "        output2 = model2(img)\n",
    "        output3 = model3(img)\n",
    "        preds = torch.stack([output1,output2,output3])\n",
    "        _, all_preds = preds.max(-1)\n",
    "        label_matrix = (all_preds == target).float().T\n",
    "        logit = label_matrix.T.unsqueeze(2).repeat(1,1,1000) * preds.softmax(dim=-1)\n",
    "        weighted_ensem = logit.sum(dim=0)\n",
    "        naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "        _, w_ensem_pred = weighted_ensem.max(-1)\n",
    "        _, n_ensem_pred = naive_ensem.max(-1)\n",
    "        w_acc += (w_ensem_pred == target).sum()\n",
    "        n_acc += (n_ensem_pred == target).sum()\n",
    "    targets.append(label_matrix)\n",
    "    \n",
    "print(w_acc/len(val_dataset), n_acc/len(val_dataset))\n",
    "print(len(targets), targets[0].shape, targets[-1].shape)\n",
    "all_targets = torch.cat(targets)\n",
    "print(all_targets.shape)\n",
    "num_correct = all_targets.sum(-1)\n",
    "print((num_correct == 3).sum())\n",
    "print((num_correct == 2).sum())\n",
    "print((num_correct == 1).sum())\n",
    "print((num_correct == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "featured-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = models.resnet18(num_classes=3).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(gate.parameters(), lr=0.5, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\\n",
    "        patience=1, verbose=True, threshold=0.01, factor = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "proper-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 0/38: 0.33700257539749146\n",
      "Epoch 0 | Step 10/38: 0.12781676650047302\n",
      "Epoch 0 | Step 20/38: 0.12650315463542938\n",
      "Epoch 0 | Step 30/38: 0.12327754497528076\n",
      "out: tensor([[0.3328, 0.3340, 0.3332],\n",
      "        [0.3328, 0.3340, 0.3332],\n",
      "        [0.3327, 0.3340, 0.3333],\n",
      "        [0.3328, 0.3340, 0.3332],\n",
      "        [0.3329, 0.3340, 0.3331],\n",
      "        [0.3331, 0.3341, 0.3328],\n",
      "        [0.3323, 0.3334, 0.3343],\n",
      "        [0.3328, 0.3340, 0.3332],\n",
      "        [0.3328, 0.3340, 0.3332],\n",
      "        [0.3329, 0.3340, 0.3331]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 0 completed. Avg loss: 0.1321294754743576\n",
      "Epoch 1 | Step 0/38: 0.1251874417066574\n",
      "Epoch 1 | Step 10/38: 0.1278020292520523\n",
      "Epoch 1 | Step 20/38: 0.12649115920066833\n",
      "Epoch 1 | Step 30/38: 0.12326105684041977\n",
      "out: tensor([[0.3326, 0.3347, 0.3327],\n",
      "        [0.3326, 0.3347, 0.3327],\n",
      "        [0.3325, 0.3347, 0.3328],\n",
      "        [0.3326, 0.3347, 0.3327],\n",
      "        [0.3327, 0.3347, 0.3326],\n",
      "        [0.3329, 0.3348, 0.3323],\n",
      "        [0.3322, 0.3339, 0.3339],\n",
      "        [0.3326, 0.3347, 0.3327],\n",
      "        [0.3326, 0.3347, 0.3327],\n",
      "        [0.3327, 0.3347, 0.3326]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 1 completed. Avg loss: 0.12653952836990356\n",
      "Epoch 2 | Step 0/38: 0.12514255940914154\n",
      "Epoch 2 | Step 10/38: 0.12778274714946747\n",
      "Epoch 2 | Step 20/38: 0.12647412717342377\n",
      "Epoch 2 | Step 30/38: 0.12324171513319016\n",
      "out: tensor([[0.3323, 0.3356, 0.3320],\n",
      "        [0.3323, 0.3356, 0.3320],\n",
      "        [0.3322, 0.3355, 0.3322],\n",
      "        [0.3323, 0.3356, 0.3320],\n",
      "        [0.3324, 0.3356, 0.3320],\n",
      "        [0.3326, 0.3358, 0.3316],\n",
      "        [0.3321, 0.3345, 0.3334],\n",
      "        [0.3323, 0.3356, 0.3320],\n",
      "        [0.3323, 0.3356, 0.3321],\n",
      "        [0.3324, 0.3357, 0.3320]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 2 completed. Avg loss: 0.12651367485523224\n",
      "Epoch 3 | Step 0/38: 0.12508566677570343\n",
      "Epoch 3 | Step 10/38: 0.12775933742523193\n",
      "Epoch 3 | Step 20/38: 0.1264551281929016\n",
      "Epoch 3 | Step 30/38: 0.12321960926055908\n",
      "Epoch     4: reducing learning rate of group 0 to 1.5000e-01.\n",
      "out: tensor([[0.3320, 0.3367, 0.3313],\n",
      "        [0.3320, 0.3367, 0.3313],\n",
      "        [0.3319, 0.3366, 0.3315],\n",
      "        [0.3320, 0.3367, 0.3313],\n",
      "        [0.3320, 0.3367, 0.3313],\n",
      "        [0.3323, 0.3368, 0.3309],\n",
      "        [0.3319, 0.3353, 0.3328],\n",
      "        [0.3320, 0.3367, 0.3313],\n",
      "        [0.3320, 0.3366, 0.3314],\n",
      "        [0.3321, 0.3367, 0.3312]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 3 completed. Avg loss: 0.1264835000038147\n",
      "Epoch 4 | Step 0/38: 0.125018909573555\n",
      "Epoch 4 | Step 10/38: 0.1277395486831665\n",
      "Epoch 4 | Step 20/38: 0.12644433975219727\n",
      "Epoch 4 | Step 30/38: 0.12320741266012192\n",
      "out: tensor([[0.3319, 0.3371, 0.3310],\n",
      "        [0.3319, 0.3371, 0.3310],\n",
      "        [0.3318, 0.3370, 0.3313],\n",
      "        [0.3319, 0.3371, 0.3310],\n",
      "        [0.3319, 0.3371, 0.3310],\n",
      "        [0.3322, 0.3372, 0.3306],\n",
      "        [0.3319, 0.3355, 0.3326],\n",
      "        [0.3319, 0.3371, 0.3310],\n",
      "        [0.3318, 0.3370, 0.3311],\n",
      "        [0.3319, 0.3371, 0.3309]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 4 completed. Avg loss: 0.12646472454071045\n",
      "Epoch 5 | Step 0/38: 0.12499552220106125\n",
      "Epoch 5 | Step 10/38: 0.1277311146259308\n",
      "Epoch 5 | Step 20/38: 0.12643784284591675\n",
      "Epoch 5 | Step 30/38: 0.12319948524236679\n",
      "Epoch     6: reducing learning rate of group 0 to 4.5000e-02.\n",
      "out: tensor([[0.3318, 0.3375, 0.3307],\n",
      "        [0.3318, 0.3375, 0.3308],\n",
      "        [0.3317, 0.3373, 0.3310],\n",
      "        [0.3318, 0.3375, 0.3308],\n",
      "        [0.3318, 0.3375, 0.3307],\n",
      "        [0.3321, 0.3376, 0.3303],\n",
      "        [0.3318, 0.3358, 0.3324],\n",
      "        [0.3318, 0.3375, 0.3307],\n",
      "        [0.3317, 0.3374, 0.3309],\n",
      "        [0.3318, 0.3375, 0.3307]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 5 completed. Avg loss: 0.126453697681427\n",
      "Epoch 6 | Step 0/38: 0.12496893107891083\n",
      "Epoch 6 | Step 10/38: 0.12772482633590698\n",
      "Epoch 6 | Step 20/38: 0.12643414735794067\n",
      "Epoch 6 | Step 30/38: 0.12319526076316833\n",
      "out: tensor([[0.3318, 0.3376, 0.3306],\n",
      "        [0.3317, 0.3376, 0.3307],\n",
      "        [0.3316, 0.3375, 0.3309],\n",
      "        [0.3317, 0.3376, 0.3307],\n",
      "        [0.3317, 0.3376, 0.3306],\n",
      "        [0.3320, 0.3378, 0.3302],\n",
      "        [0.3318, 0.3359, 0.3323],\n",
      "        [0.3317, 0.3376, 0.3306],\n",
      "        [0.3317, 0.3376, 0.3308],\n",
      "        [0.3318, 0.3377, 0.3306]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 6 completed. Avg loss: 0.12644684314727783\n",
      "Epoch 7 | Step 0/38: 0.12495984137058258\n",
      "Epoch 7 | Step 10/38: 0.1277223527431488\n",
      "Epoch 7 | Step 20/38: 0.12643197178840637\n",
      "Epoch 7 | Step 30/38: 0.12319254875183105\n",
      "Epoch     8: reducing learning rate of group 0 to 1.3500e-02.\n",
      "out: tensor([[0.3317, 0.3378, 0.3305],\n",
      "        [0.3317, 0.3377, 0.3306],\n",
      "        [0.3316, 0.3376, 0.3308],\n",
      "        [0.3317, 0.3377, 0.3306],\n",
      "        [0.3317, 0.3378, 0.3305],\n",
      "        [0.3320, 0.3379, 0.3301],\n",
      "        [0.3318, 0.3360, 0.3322],\n",
      "        [0.3317, 0.3378, 0.3305],\n",
      "        [0.3316, 0.3377, 0.3307],\n",
      "        [0.3317, 0.3378, 0.3305]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 7 completed. Avg loss: 0.12644287943840027\n",
      "Epoch 8 | Step 0/38: 0.12495003640651703\n",
      "Epoch 8 | Step 10/38: 0.12772032618522644\n",
      "Epoch 8 | Step 20/38: 0.1264307051897049\n",
      "Epoch 8 | Step 30/38: 0.12319105863571167\n",
      "out: tensor([[0.3317, 0.3378, 0.3305],\n",
      "        [0.3317, 0.3378, 0.3305],\n",
      "        [0.3316, 0.3377, 0.3308],\n",
      "        [0.3317, 0.3378, 0.3305],\n",
      "        [0.3317, 0.3378, 0.3305],\n",
      "        [0.3320, 0.3380, 0.3301],\n",
      "        [0.3318, 0.3360, 0.3322],\n",
      "        [0.3317, 0.3378, 0.3305],\n",
      "        [0.3316, 0.3377, 0.3306],\n",
      "        [0.3317, 0.3378, 0.3304]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000]], device='cuda:0')\n",
      "Epoch 8 completed. Avg loss: 0.12644042074680328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-7dbcf8468f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_val_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabel_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "w_acc = 0\n",
    "n_acc = 0\n",
    "\n",
    "for ep in range(20):\n",
    "    total_loss = 0.\n",
    "    for it, data in enumerate(zip(subset_val_loader,targets)):\n",
    "        img = (data[0][0]).cuda(non_blocking=True)\n",
    "        label_matrix = (data[1]).cuda(non_blocking=True)\n",
    "        label_matrix = F.normalize(label_matrix, p =1)\n",
    "        gate_out = gate(img)\n",
    "        gate_out = F.normalize(gate_out, p =1)\n",
    "        loss = F.mse_loss(gate_out,label_matrix)\n",
    "        total_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if it % 10 == 0:\n",
    "            print(f\"Epoch {ep} | Step {it}/{len(subset_val_loader)}: {loss.item()}\")\n",
    "    total_loss /= len(subset_val_loader)\n",
    "    scheduler.step(total_loss)\n",
    "    print(\"out:\", gate_out[:3])\n",
    "    print(\"target:\", label_matrix[:3])\n",
    "    \n",
    "    print(f\"Epoch {ep} completed. Avg loss: {total_loss}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = models.resnet18(num_classes=3).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(gate.parameters(), lr=0.5, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\\n",
    "        patience=1, verbose=True, threshold=0.01, factor = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "accepted-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 0/40: 47.265625\n",
      "Epoch 0 | Step 10/40: 47.786460876464844\n",
      "Epoch 0 | Step 20/40: 47.52604293823242\n",
      "Epoch 0 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 0 completed. Avg loss: 45.15951156616211\n",
      "Epoch 1 | Step 0/40: 47.265625\n",
      "Epoch 1 | Step 10/40: 47.786460876464844\n",
      "Epoch 1 | Step 20/40: 47.52604293823242\n",
      "Epoch 1 | Step 30/40: 46.875\n",
      "Epoch    12: reducing learning rate of group 0 to 1.2150e-03.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 1 completed. Avg loss: 45.15951156616211\n",
      "Epoch 2 | Step 0/40: 47.265625\n",
      "Epoch 2 | Step 10/40: 47.786460876464844\n",
      "Epoch 2 | Step 20/40: 47.52604293823242\n",
      "Epoch 2 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 2 completed. Avg loss: 45.15951156616211\n",
      "Epoch 3 | Step 0/40: 47.265625\n",
      "Epoch 3 | Step 10/40: 47.786460876464844\n",
      "Epoch 3 | Step 20/40: 47.52604293823242\n",
      "Epoch 3 | Step 30/40: 46.875\n",
      "Epoch    14: reducing learning rate of group 0 to 3.6450e-04.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 3 completed. Avg loss: 45.15951156616211\n",
      "Epoch 4 | Step 0/40: 47.265625\n",
      "Epoch 4 | Step 10/40: 47.786460876464844\n",
      "Epoch 4 | Step 20/40: 47.52604293823242\n",
      "Epoch 4 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 4 completed. Avg loss: 45.15951156616211\n",
      "Epoch 5 | Step 0/40: 47.265625\n",
      "Epoch 5 | Step 10/40: 47.786460876464844\n",
      "Epoch 5 | Step 20/40: 47.52604293823242\n",
      "Epoch 5 | Step 30/40: 46.875\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0935e-04.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 5 completed. Avg loss: 45.15951156616211\n",
      "Epoch 6 | Step 0/40: 47.265625\n",
      "Epoch 6 | Step 10/40: 47.786460876464844\n",
      "Epoch 6 | Step 20/40: 47.52604293823242\n",
      "Epoch 6 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 6 completed. Avg loss: 45.15951156616211\n",
      "Epoch 7 | Step 0/40: 47.265625\n",
      "Epoch 7 | Step 10/40: 47.786460876464844\n",
      "Epoch 7 | Step 20/40: 47.52604293823242\n",
      "Epoch 7 | Step 30/40: 46.875\n",
      "Epoch    18: reducing learning rate of group 0 to 3.2805e-05.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 7 completed. Avg loss: 45.15951156616211\n",
      "Epoch 8 | Step 0/40: 47.265625\n",
      "Epoch 8 | Step 10/40: 47.786460876464844\n",
      "Epoch 8 | Step 20/40: 47.52604293823242\n",
      "Epoch 8 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 8 completed. Avg loss: 45.15951156616211\n",
      "Epoch 9 | Step 0/40: 47.265625\n",
      "Epoch 9 | Step 10/40: 47.786460876464844\n",
      "Epoch 9 | Step 20/40: 47.52604293823242\n",
      "Epoch 9 | Step 30/40: 46.875\n",
      "Epoch    20: reducing learning rate of group 0 to 9.8415e-06.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 9 completed. Avg loss: 45.15951156616211\n",
      "Epoch 10 | Step 0/40: 47.265625\n",
      "Epoch 10 | Step 10/40: 47.786460876464844\n",
      "Epoch 10 | Step 20/40: 47.52604293823242\n",
      "Epoch 10 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 10 completed. Avg loss: 45.15951156616211\n",
      "Epoch 11 | Step 0/40: 47.265625\n",
      "Epoch 11 | Step 10/40: 47.786460876464844\n",
      "Epoch 11 | Step 20/40: 47.52604293823242\n",
      "Epoch 11 | Step 30/40: 46.875\n",
      "Epoch    22: reducing learning rate of group 0 to 2.9524e-06.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 11 completed. Avg loss: 45.15951156616211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Step 0/40: 47.265625\n",
      "Epoch 12 | Step 10/40: 47.786460876464844\n",
      "Epoch 12 | Step 20/40: 47.52604293823242\n",
      "Epoch 12 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 12 completed. Avg loss: 45.15951156616211\n",
      "Epoch 13 | Step 0/40: 47.265625\n",
      "Epoch 13 | Step 10/40: 47.786460876464844\n",
      "Epoch 13 | Step 20/40: 47.52604293823242\n",
      "Epoch 13 | Step 30/40: 46.875\n",
      "Epoch    24: reducing learning rate of group 0 to 8.8573e-07.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 13 completed. Avg loss: 45.15951156616211\n",
      "Epoch 14 | Step 0/40: 47.265625\n",
      "Epoch 14 | Step 10/40: 47.786460876464844\n",
      "Epoch 14 | Step 20/40: 47.52604293823242\n",
      "Epoch 14 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 14 completed. Avg loss: 45.15951156616211\n",
      "Epoch 15 | Step 0/40: 47.265625\n",
      "Epoch 15 | Step 10/40: 47.786460876464844\n",
      "Epoch 15 | Step 20/40: 47.52604293823242\n",
      "Epoch 15 | Step 30/40: 46.875\n",
      "Epoch    26: reducing learning rate of group 0 to 2.6572e-07.\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 15 completed. Avg loss: 45.15951156616211\n",
      "Epoch 16 | Step 0/40: 47.265625\n",
      "Epoch 16 | Step 10/40: 47.786460876464844\n",
      "Epoch 16 | Step 20/40: 47.52604293823242\n",
      "Epoch 16 | Step 30/40: 46.875\n",
      "out: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0')\n",
      "Epoch 16 completed. Avg loss: 45.15951156616211\n",
      "Epoch 17 | Step 0/40: 47.265625\n",
      "Epoch 17 | Step 10/40: 47.786460876464844\n",
      "Epoch 17 | Step 20/40: 47.52604293823242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-4b451b9b9597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {ep} | Step {it}/{len(val_loader)}: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### BCE LOSS ##\n",
    "\n",
    "# train loop\n",
    "w_acc = 0\n",
    "n_acc = 0\n",
    "criterion = torch.nn.BCELoss()\n",
    "for ep in range(100):\n",
    "    total_loss = 0.\n",
    "    for it, data in enumerate(zip(subset_val_loader,targets)):\n",
    "        img = (data[0][0]).cuda(non_blocking=True)\n",
    "        label_matrix = (data[1]).cuda(non_blocking=True)\n",
    "        gate_out = gate(img)\n",
    "        sig_out = torch.sigmoid(gate_out)\n",
    "        loss = criterion(sig_out,label_matrix)\n",
    "        total_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if it % 10 == 0:\n",
    "            print(f\"Epoch {ep} | Step {it}/{len(val_loader)}: {loss.item()}\")\n",
    "    total_loss /= len(val_loader)\n",
    "    scheduler.step(total_loss)\n",
    "    print(\"out:\", sig_out[:3])\n",
    "    print(\"target:\", label_matrix[:3])\n",
    "    \n",
    "    print(f\"Epoch {ep} completed. Avg loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interior-talent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 torch.Size([256, 3]) torch.Size([232, 3])\n",
      "torch.Size([1000, 3]) tensor(0, device='cuda:0') tensor(568, device='cuda:0') tensor(432, device='cuda:0') tensor(0, device='cuda:0')\n",
      "Epoch 0 | Step 0/4: 0.7243248224258423\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 0 completed. Avg loss: 36.323997497558594\n",
      "Epoch 1 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 1 completed. Avg loss: 48.28484344482422\n",
      "Epoch 2 | Step 0/4: 48.567710876464844\n",
      "Epoch     3: reducing learning rate of group 0 to 1.5000e-01.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 2 completed. Avg loss: 48.28484344482422\n",
      "Epoch 3 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 3 completed. Avg loss: 48.28484344482422\n",
      "Epoch 4 | Step 0/4: 48.567710876464844\n",
      "Epoch     5: reducing learning rate of group 0 to 4.5000e-02.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 4 completed. Avg loss: 48.28484344482422\n",
      "Epoch 5 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 5 completed. Avg loss: 48.28484344482422\n",
      "Epoch 6 | Step 0/4: 48.567710876464844\n",
      "Epoch     7: reducing learning rate of group 0 to 1.3500e-02.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 6 completed. Avg loss: 48.28484344482422\n",
      "Epoch 7 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 7 completed. Avg loss: 48.28484344482422\n",
      "Epoch 8 | Step 0/4: 48.567710876464844\n",
      "Epoch     9: reducing learning rate of group 0 to 4.0500e-03.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 8 completed. Avg loss: 48.28484344482422\n",
      "Epoch 9 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 9 completed. Avg loss: 48.28484344482422\n",
      "Epoch 10 | Step 0/4: 48.567710876464844\n",
      "Epoch    11: reducing learning rate of group 0 to 1.2150e-03.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 10 completed. Avg loss: 48.28484344482422\n",
      "Epoch 11 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 11 completed. Avg loss: 48.28484344482422\n",
      "Epoch 12 | Step 0/4: 48.567710876464844\n",
      "Epoch    13: reducing learning rate of group 0 to 3.6450e-04.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 12 completed. Avg loss: 48.28484344482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 13 completed. Avg loss: 48.28484344482422\n",
      "Epoch 14 | Step 0/4: 48.567710876464844\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0935e-04.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 14 completed. Avg loss: 48.28484344482422\n",
      "Epoch 15 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 15 completed. Avg loss: 48.28484344482422\n",
      "Epoch 16 | Step 0/4: 48.567710876464844\n",
      "Epoch    17: reducing learning rate of group 0 to 3.2805e-05.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 16 completed. Avg loss: 48.28484344482422\n",
      "Epoch 17 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 17 completed. Avg loss: 48.28484344482422\n",
      "Epoch 18 | Step 0/4: 48.567710876464844\n",
      "Epoch    19: reducing learning rate of group 0 to 9.8415e-06.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 18 completed. Avg loss: 48.28484344482422\n",
      "Epoch 19 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 19 completed. Avg loss: 48.28484344482422\n",
      "Epoch 20 | Step 0/4: 48.567710876464844\n",
      "Epoch    21: reducing learning rate of group 0 to 2.9524e-06.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 20 completed. Avg loss: 48.28484344482422\n",
      "Epoch 21 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 21 completed. Avg loss: 48.28484344482422\n",
      "Epoch 22 | Step 0/4: 48.567710876464844\n",
      "Epoch    23: reducing learning rate of group 0 to 8.8573e-07.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 22 completed. Avg loss: 48.28484344482422\n",
      "Epoch 23 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 23 completed. Avg loss: 48.28484344482422\n",
      "Epoch 24 | Step 0/4: 48.567710876464844\n",
      "Epoch    25: reducing learning rate of group 0 to 2.6572e-07.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 24 completed. Avg loss: 48.28484344482422\n",
      "Epoch 25 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 25 completed. Avg loss: 48.28484344482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Step 0/4: 48.567710876464844\n",
      "Epoch    27: reducing learning rate of group 0 to 7.9716e-08.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 26 completed. Avg loss: 48.28484344482422\n",
      "Epoch 27 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 27 completed. Avg loss: 48.28484344482422\n",
      "Epoch 28 | Step 0/4: 48.567710876464844\n",
      "Epoch    29: reducing learning rate of group 0 to 2.3915e-08.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 28 completed. Avg loss: 48.28484344482422\n",
      "Epoch 29 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 29 completed. Avg loss: 48.28484344482422\n",
      "Epoch 30 | Step 0/4: 48.567710876464844\n",
      "Epoch    31: reducing learning rate of group 0 to 7.1745e-09.\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 30 completed. Avg loss: 48.28484344482422\n",
      "Epoch 31 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 31 completed. Avg loss: 48.28484344482422\n",
      "Epoch 32 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 32 completed. Avg loss: 48.28484344482422\n",
      "Epoch 33 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 33 completed. Avg loss: 48.28484344482422\n",
      "Epoch 34 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 34 completed. Avg loss: 48.28484344482422\n",
      "Epoch 35 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 35 completed. Avg loss: 48.28484344482422\n",
      "Epoch 36 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 36 completed. Avg loss: 48.28484344482422\n",
      "Epoch 37 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 37 completed. Avg loss: 48.28484344482422\n",
      "Epoch 38 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 38 completed. Avg loss: 48.28484344482422\n",
      "Epoch 39 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 39 completed. Avg loss: 48.28484344482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 40 completed. Avg loss: 48.28484344482422\n",
      "Epoch 41 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 41 completed. Avg loss: 48.28484344482422\n",
      "Epoch 42 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 42 completed. Avg loss: 48.28484344482422\n",
      "Epoch 43 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 43 completed. Avg loss: 48.28484344482422\n",
      "Epoch 44 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 44 completed. Avg loss: 48.28484344482422\n",
      "Epoch 45 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 45 completed. Avg loss: 48.28484344482422\n",
      "Epoch 46 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 46 completed. Avg loss: 48.28484344482422\n",
      "Epoch 47 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 47 completed. Avg loss: 48.28484344482422\n",
      "Epoch 48 | Step 0/4: 48.567710876464844\n",
      "out: tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "target: tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.]], device='cuda:0')\n",
      "Epoch 48 completed. Avg loss: 48.28484344482422\n",
      "Epoch 49 | Step 0/4: 48.567710876464844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6f9d6c8cd8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {ep} | Step {it}/{len(subsubset_val_loader)}: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsubset_val_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"target:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, metrics, epoch)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m# convert `metrics` to float, in case it's a zero-dim Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_ds = Split_Dataset('/gpfs/u/locker/200/CADS/datasets/ImageNet',  \\\n",
    "                    f'./calib_splits/am_imagenet_5percent_val.txt',\n",
    "                    transform=val_transforms)\n",
    "subsubset_val = Subset(val_ds, list(indices)[:1000])\n",
    "\n",
    "subsubset_val_loader = torch.utils.data.DataLoader(\n",
    "            subsubset_val, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "\n",
    "w_acc = 0\n",
    "n_acc = 0\n",
    "\n",
    "targets = []\n",
    "for it, (img, target) in enumerate(subsubset_val_loader):\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        output1 = model1(img)\n",
    "        output2 = model2(img)\n",
    "        output3 = model3(img)\n",
    "        preds = torch.stack([output1,output2,output3])\n",
    "        _, all_preds = preds.max(-1)\n",
    "        label_matrix = (all_preds == target).float().T\n",
    "    targets.append(label_matrix)\n",
    "    \n",
    "print(len(targets), targets[0].shape, targets[-1].shape)\n",
    "all_targets = torch.cat(targets)\n",
    "num_correct = all_targets.sum(-1)\n",
    "print(all_targets.shape, (num_correct == 3).sum(), (num_correct == 2).sum(), (num_correct == 1).sum(), (num_correct == 0).sum())\n",
    "\n",
    "gate = models.resnet18(num_classes=3).cuda()\n",
    "optimizer = torch.optim.Adam(gate.parameters(), lr=0.5, weight_decay=0.)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\\n",
    "        patience=1, verbose=True, threshold=0.01, factor = 0.3)\n",
    "\n",
    "### BCE LOSS ##\n",
    "\n",
    "# train loop\n",
    "w_acc = 0\n",
    "n_acc = 0\n",
    "criterion = torch.nn.BCELoss()\n",
    "for ep in range(100):\n",
    "    total_loss = 0.\n",
    "    for it, data in enumerate(zip(subsubset_val_loader,targets)):\n",
    "        img = (data[0][0]).cuda(non_blocking=True)\n",
    "        label_matrix = (data[1]).cuda(non_blocking=True)\n",
    "        gate_out = gate(img)\n",
    "        sig_out = torch.sigmoid(gate_out)\n",
    "        loss = criterion(sig_out,label_matrix)\n",
    "        total_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if it % 10 == 0:\n",
    "            print(f\"Epoch {ep} | Step {it}/{len(subsubset_val_loader)}: {loss.item()}\")\n",
    "    total_loss /= len(subsubset_val_loader)\n",
    "    scheduler.step(total_loss)\n",
    "    print(\"out:\", sig_out[:10])\n",
    "    print(\"target:\", label_matrix[:10])\n",
    "    \n",
    "    print(f\"Epoch {ep} completed. Avg loss: {total_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emerging-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load(\"./dist_models/ft95perc_baseR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model1.load_state_dict(ckpt)\n",
    "model1.eval()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_eqR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model2.load_state_dict(ckpt)\n",
    "model2.eval()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_inv_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model3.load_state_dict(ckpt)\n",
    "model3.eval()\n",
    "model1=model1.cuda()\n",
    "model2=model2.cuda()\n",
    "model3=model3.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-issue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "standard-balance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(236, device='cuda:0') tensor(223, device='cuda:0')\n",
      "tensor(456, device='cuda:0') tensor(431, device='cuda:0')\n",
      "tensor(683, device='cuda:0') tensor(652, device='cuda:0')\n",
      "tensor(904, device='cuda:0') tensor(862, device='cuda:0')\n",
      "tensor(1130, device='cuda:0') tensor(1076, device='cuda:0')\n",
      "tensor(1357, device='cuda:0') tensor(1290, device='cuda:0')\n",
      "tensor(1572, device='cuda:0') tensor(1492, device='cuda:0')\n",
      "tensor(1799, device='cuda:0') tensor(1706, device='cuda:0')\n",
      "tensor(2028, device='cuda:0') tensor(1923, device='cuda:0')\n",
      "tensor(2246, device='cuda:0') tensor(2126, device='cuda:0')\n",
      "tensor(2470, device='cuda:0') tensor(2341, device='cuda:0')\n",
      "tensor(2683, device='cuda:0') tensor(2548, device='cuda:0')\n",
      "tensor(2903, device='cuda:0') tensor(2752, device='cuda:0')\n",
      "tensor(3119, device='cuda:0') tensor(2957, device='cuda:0')\n",
      "tensor(3336, device='cuda:0') tensor(3166, device='cuda:0')\n",
      "tensor(3555, device='cuda:0') tensor(3371, device='cuda:0')\n",
      "tensor(3776, device='cuda:0') tensor(3578, device='cuda:0')\n",
      "tensor(3998, device='cuda:0') tensor(3787, device='cuda:0')\n",
      "tensor(4214, device='cuda:0') tensor(3994, device='cuda:0')\n",
      "tensor(4435, device='cuda:0') tensor(4205, device='cuda:0')\n",
      "tensor(4661, device='cuda:0') tensor(4417, device='cuda:0')\n",
      "tensor(4885, device='cuda:0') tensor(4627, device='cuda:0')\n",
      "tensor(5106, device='cuda:0') tensor(4837, device='cuda:0')\n",
      "tensor(5324, device='cuda:0') tensor(5047, device='cuda:0')\n",
      "tensor(5541, device='cuda:0') tensor(5256, device='cuda:0')\n",
      "tensor(5756, device='cuda:0') tensor(5463, device='cuda:0')\n",
      "tensor(5981, device='cuda:0') tensor(5680, device='cuda:0')\n",
      "tensor(6207, device='cuda:0') tensor(5893, device='cuda:0')\n",
      "tensor(6435, device='cuda:0') tensor(6108, device='cuda:0')\n",
      "tensor(6659, device='cuda:0') tensor(6322, device='cuda:0')\n",
      "tensor(6882, device='cuda:0') tensor(6536, device='cuda:0')\n",
      "tensor(7105, device='cuda:0') tensor(6745, device='cuda:0')\n",
      "tensor(7344, device='cuda:0') tensor(6968, device='cuda:0')\n",
      "tensor(7563, device='cuda:0') tensor(7169, device='cuda:0')\n",
      "tensor(7773, device='cuda:0') tensor(7365, device='cuda:0')\n",
      "tensor(7992, device='cuda:0') tensor(7571, device='cuda:0')\n",
      "tensor(8218, device='cuda:0') tensor(7782, device='cuda:0')\n",
      "tensor(8429, device='cuda:0') tensor(7977, device='cuda:0')\n",
      "tensor(8661, device='cuda:0') tensor(8193, device='cuda:0')\n",
      "tensor(8869, device='cuda:0') tensor(8391, device='cuda:0')\n",
      "tensor(9100, device='cuda:0') tensor(8609, device='cuda:0')\n",
      "tensor(9317, device='cuda:0') tensor(8810, device='cuda:0')\n",
      "tensor(9542, device='cuda:0') tensor(9027, device='cuda:0')\n",
      "tensor(9759, device='cuda:0') tensor(9233, device='cuda:0')\n",
      "tensor(9992, device='cuda:0') tensor(9455, device='cuda:0')\n",
      "tensor(10210, device='cuda:0') tensor(9663, device='cuda:0')\n",
      "tensor(10434, device='cuda:0') tensor(9874, device='cuda:0')\n",
      "tensor(10661, device='cuda:0') tensor(10096, device='cuda:0')\n",
      "tensor(10889, device='cuda:0') tensor(10312, device='cuda:0')\n",
      "tensor(11114, device='cuda:0') tensor(10521, device='cuda:0')\n",
      "tensor(11337, device='cuda:0') tensor(10732, device='cuda:0')\n",
      "tensor(11563, device='cuda:0') tensor(10948, device='cuda:0')\n",
      "tensor(11790, device='cuda:0') tensor(11161, device='cuda:0')\n",
      "tensor(12018, device='cuda:0') tensor(11376, device='cuda:0')\n",
      "tensor(12239, device='cuda:0') tensor(11583, device='cuda:0')\n",
      "tensor(12461, device='cuda:0') tensor(11794, device='cuda:0')\n",
      "tensor(12688, device='cuda:0') tensor(12007, device='cuda:0')\n",
      "tensor(12914, device='cuda:0') tensor(12221, device='cuda:0')\n",
      "tensor(13126, device='cuda:0') tensor(12421, device='cuda:0')\n",
      "tensor(13348, device='cuda:0') tensor(12632, device='cuda:0')\n",
      "tensor(13564, device='cuda:0') tensor(12838, device='cuda:0')\n",
      "tensor(13782, device='cuda:0') tensor(13041, device='cuda:0')\n",
      "tensor(14014, device='cuda:0') tensor(13259, device='cuda:0')\n",
      "tensor(14227, device='cuda:0') tensor(13466, device='cuda:0')\n",
      "tensor(14445, device='cuda:0') tensor(13676, device='cuda:0')\n",
      "tensor(14665, device='cuda:0') tensor(13886, device='cuda:0')\n",
      "tensor(14886, device='cuda:0') tensor(14095, device='cuda:0')\n",
      "tensor(15107, device='cuda:0') tensor(14300, device='cuda:0')\n",
      "tensor(15328, device='cuda:0') tensor(14511, device='cuda:0')\n",
      "tensor(15551, device='cuda:0') tensor(14725, device='cuda:0')\n",
      "tensor(15773, device='cuda:0') tensor(14940, device='cuda:0')\n",
      "tensor(15989, device='cuda:0') tensor(15145, device='cuda:0')\n",
      "tensor(16210, device='cuda:0') tensor(15355, device='cuda:0')\n",
      "tensor(16438, device='cuda:0') tensor(15575, device='cuda:0')\n",
      "tensor(16660, device='cuda:0') tensor(15784, device='cuda:0')\n",
      "tensor(16886, device='cuda:0') tensor(15999, device='cuda:0')\n",
      "tensor(17109, device='cuda:0') tensor(16212, device='cuda:0')\n",
      "tensor(17327, device='cuda:0') tensor(16415, device='cuda:0')\n",
      "tensor(17549, device='cuda:0') tensor(16625, device='cuda:0')\n",
      "tensor(17765, device='cuda:0') tensor(16825, device='cuda:0')\n",
      "tensor(17993, device='cuda:0') tensor(17035, device='cuda:0')\n",
      "tensor(18224, device='cuda:0') tensor(17257, device='cuda:0')\n",
      "tensor(18442, device='cuda:0') tensor(17462, device='cuda:0')\n",
      "tensor(18668, device='cuda:0') tensor(17675, device='cuda:0')\n",
      "tensor(18890, device='cuda:0') tensor(17888, device='cuda:0')\n",
      "tensor(19110, device='cuda:0') tensor(18097, device='cuda:0')\n",
      "tensor(19326, device='cuda:0') tensor(18298, device='cuda:0')\n",
      "tensor(19537, device='cuda:0') tensor(18497, device='cuda:0')\n",
      "tensor(19748, device='cuda:0') tensor(18697, device='cuda:0')\n",
      "tensor(19966, device='cuda:0') tensor(18905, device='cuda:0')\n",
      "tensor(20187, device='cuda:0') tensor(19117, device='cuda:0')\n",
      "tensor(20408, device='cuda:0') tensor(19321, device='cuda:0')\n",
      "tensor(20625, device='cuda:0') tensor(19524, device='cuda:0')\n",
      "tensor(20841, device='cuda:0') tensor(19728, device='cuda:0')\n",
      "tensor(21061, device='cuda:0') tensor(19937, device='cuda:0')\n",
      "tensor(21284, device='cuda:0') tensor(20148, device='cuda:0')\n",
      "tensor(21508, device='cuda:0') tensor(20362, device='cuda:0')\n",
      "tensor(21721, device='cuda:0') tensor(20563, device='cuda:0')\n",
      "tensor(21935, device='cuda:0') tensor(20759, device='cuda:0')\n",
      "tensor(22163, device='cuda:0') tensor(20972, device='cuda:0')\n",
      "tensor(22385, device='cuda:0') tensor(21179, device='cuda:0')\n",
      "tensor(22613, device='cuda:0') tensor(21395, device='cuda:0')\n",
      "tensor(22838, device='cuda:0') tensor(21602, device='cuda:0')\n",
      "tensor(23069, device='cuda:0') tensor(21822, device='cuda:0')\n",
      "tensor(23298, device='cuda:0') tensor(22037, device='cuda:0')\n",
      "tensor(23522, device='cuda:0') tensor(22250, device='cuda:0')\n",
      "tensor(23749, device='cuda:0') tensor(22463, device='cuda:0')\n",
      "tensor(23975, device='cuda:0') tensor(22680, device='cuda:0')\n",
      "tensor(24193, device='cuda:0') tensor(22888, device='cuda:0')\n",
      "tensor(24415, device='cuda:0') tensor(23097, device='cuda:0')\n",
      "tensor(24643, device='cuda:0') tensor(23312, device='cuda:0')\n",
      "tensor(24855, device='cuda:0') tensor(23512, device='cuda:0')\n",
      "tensor(25086, device='cuda:0') tensor(23724, device='cuda:0')\n",
      "tensor(25312, device='cuda:0') tensor(23938, device='cuda:0')\n",
      "tensor(25531, device='cuda:0') tensor(24146, device='cuda:0')\n",
      "tensor(25750, device='cuda:0') tensor(24356, device='cuda:0')\n",
      "tensor(25971, device='cuda:0') tensor(24560, device='cuda:0')\n",
      "tensor(26200, device='cuda:0') tensor(24773, device='cuda:0')\n",
      "tensor(26417, device='cuda:0') tensor(24982, device='cuda:0')\n",
      "tensor(26640, device='cuda:0') tensor(25192, device='cuda:0')\n",
      "tensor(26864, device='cuda:0') tensor(25403, device='cuda:0')\n",
      "tensor(27085, device='cuda:0') tensor(25605, device='cuda:0')\n",
      "tensor(27308, device='cuda:0') tensor(25821, device='cuda:0')\n",
      "tensor(27532, device='cuda:0') tensor(26036, device='cuda:0')\n",
      "tensor(27763, device='cuda:0') tensor(26257, device='cuda:0')\n",
      "tensor(27980, device='cuda:0') tensor(26461, device='cuda:0')\n",
      "tensor(28210, device='cuda:0') tensor(26673, device='cuda:0')\n",
      "tensor(28431, device='cuda:0') tensor(26887, device='cuda:0')\n",
      "tensor(28648, device='cuda:0') tensor(27093, device='cuda:0')\n",
      "tensor(28868, device='cuda:0') tensor(27310, device='cuda:0')\n",
      "tensor(29090, device='cuda:0') tensor(27519, device='cuda:0')\n",
      "tensor(29315, device='cuda:0') tensor(27732, device='cuda:0')\n",
      "tensor(29539, device='cuda:0') tensor(27947, device='cuda:0')\n",
      "tensor(29761, device='cuda:0') tensor(28162, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29975, device='cuda:0') tensor(28365, device='cuda:0')\n",
      "tensor(30202, device='cuda:0') tensor(28576, device='cuda:0')\n",
      "tensor(30431, device='cuda:0') tensor(28789, device='cuda:0')\n",
      "tensor(30648, device='cuda:0') tensor(29000, device='cuda:0')\n",
      "tensor(30867, device='cuda:0') tensor(29210, device='cuda:0')\n",
      "tensor(31090, device='cuda:0') tensor(29421, device='cuda:0')\n",
      "tensor(31314, device='cuda:0') tensor(29632, device='cuda:0')\n",
      "tensor(31536, device='cuda:0') tensor(29840, device='cuda:0')\n",
      "tensor(31752, device='cuda:0') tensor(30044, device='cuda:0')\n",
      "tensor(31970, device='cuda:0') tensor(30253, device='cuda:0')\n",
      "tensor(32197, device='cuda:0') tensor(30466, device='cuda:0')\n",
      "tensor(32421, device='cuda:0') tensor(30676, device='cuda:0')\n",
      "tensor(32644, device='cuda:0') tensor(30890, device='cuda:0')\n",
      "tensor(32864, device='cuda:0') tensor(31097, device='cuda:0')\n",
      "tensor(33079, device='cuda:0') tensor(31300, device='cuda:0')\n",
      "tensor(33306, device='cuda:0') tensor(31514, device='cuda:0')\n",
      "tensor(33523, device='cuda:0') tensor(31720, device='cuda:0')\n",
      "tensor(33734, device='cuda:0') tensor(31923, device='cuda:0')\n",
      "tensor(33953, device='cuda:0') tensor(32131, device='cuda:0')\n",
      "tensor(34165, device='cuda:0') tensor(32331, device='cuda:0')\n",
      "tensor(34389, device='cuda:0') tensor(32544, device='cuda:0')\n",
      "tensor(34617, device='cuda:0') tensor(32754, device='cuda:0')\n",
      "tensor(34836, device='cuda:0') tensor(32959, device='cuda:0')\n",
      "tensor(35056, device='cuda:0') tensor(33172, device='cuda:0')\n",
      "tensor(35277, device='cuda:0') tensor(33383, device='cuda:0')\n",
      "tensor(35507, device='cuda:0') tensor(33596, device='cuda:0')\n",
      "tensor(35731, device='cuda:0') tensor(33816, device='cuda:0')\n",
      "tensor(35959, device='cuda:0') tensor(34034, device='cuda:0')\n",
      "tensor(36185, device='cuda:0') tensor(34248, device='cuda:0')\n",
      "tensor(36399, device='cuda:0') tensor(34454, device='cuda:0')\n",
      "tensor(36623, device='cuda:0') tensor(34667, device='cuda:0')\n",
      "tensor(36851, device='cuda:0') tensor(34883, device='cuda:0')\n",
      "tensor(37079, device='cuda:0') tensor(35100, device='cuda:0')\n",
      "tensor(37304, device='cuda:0') tensor(35320, device='cuda:0')\n",
      "tensor(37527, device='cuda:0') tensor(35525, device='cuda:0')\n",
      "tensor(37745, device='cuda:0') tensor(35727, device='cuda:0')\n",
      "tensor(37960, device='cuda:0') tensor(35925, device='cuda:0')\n",
      "tensor(38180, device='cuda:0') tensor(36137, device='cuda:0')\n",
      "tensor(38396, device='cuda:0') tensor(36336, device='cuda:0')\n",
      "tensor(38613, device='cuda:0') tensor(36541, device='cuda:0')\n",
      "tensor(38835, device='cuda:0') tensor(36742, device='cuda:0')\n",
      "tensor(39068, device='cuda:0') tensor(36968, device='cuda:0')\n",
      "tensor(39292, device='cuda:0') tensor(37179, device='cuda:0')\n",
      "tensor(39500, device='cuda:0') tensor(37374, device='cuda:0')\n",
      "tensor(39725, device='cuda:0') tensor(37588, device='cuda:0')\n",
      "tensor(39938, device='cuda:0') tensor(37790, device='cuda:0')\n",
      "tensor(40159, device='cuda:0') tensor(37998, device='cuda:0')\n",
      "tensor(40369, device='cuda:0') tensor(38197, device='cuda:0')\n",
      "tensor(40582, device='cuda:0') tensor(38399, device='cuda:0')\n",
      "tensor(40806, device='cuda:0') tensor(38616, device='cuda:0')\n",
      "tensor(41040, device='cuda:0') tensor(38836, device='cuda:0')\n",
      "tensor(41262, device='cuda:0') tensor(39051, device='cuda:0')\n",
      "tensor(41490, device='cuda:0') tensor(39275, device='cuda:0')\n",
      "tensor(41714, device='cuda:0') tensor(39485, device='cuda:0')\n",
      "tensor(41933, device='cuda:0') tensor(39689, device='cuda:0')\n",
      "tensor(42152, device='cuda:0') tensor(39896, device='cuda:0')\n",
      "tensor(42382, device='cuda:0') tensor(40111, device='cuda:0')\n",
      "tensor(42603, device='cuda:0') tensor(40317, device='cuda:0')\n",
      "tensor(42827, device='cuda:0') tensor(40527, device='cuda:0')\n",
      "tensor(43046, device='cuda:0') tensor(40739, device='cuda:0')\n",
      "tensor(43271, device='cuda:0') tensor(40957, device='cuda:0')\n",
      "tensor(43494, device='cuda:0') tensor(41163, device='cuda:0')\n",
      "tensor(43713, device='cuda:0') tensor(41372, device='cuda:0')\n",
      "tensor(43932, device='cuda:0') tensor(41575, device='cuda:0')\n",
      "tensor(44155, device='cuda:0') tensor(41788, device='cuda:0')\n",
      "tensor(44376, device='cuda:0') tensor(41997, device='cuda:0')\n",
      "tensor(44597, device='cuda:0') tensor(42203, device='cuda:0')\n",
      "tensor(44819, device='cuda:0') tensor(42415, device='cuda:0')\n",
      "tensor(45043, device='cuda:0') tensor(42625, device='cuda:0')\n",
      "tensor(45265, device='cuda:0') tensor(42830, device='cuda:0')\n",
      "tensor(45487, device='cuda:0') tensor(43041, device='cuda:0')\n",
      "tensor(45714, device='cuda:0') tensor(43255, device='cuda:0')\n",
      "tensor(45947, device='cuda:0') tensor(43472, device='cuda:0')\n",
      "tensor(46173, device='cuda:0') tensor(43682, device='cuda:0')\n",
      "tensor(46396, device='cuda:0') tensor(43900, device='cuda:0')\n",
      "tensor(46617, device='cuda:0') tensor(44111, device='cuda:0')\n",
      "tensor(46842, device='cuda:0') tensor(44327, device='cuda:0')\n",
      "tensor(47060, device='cuda:0') tensor(44538, device='cuda:0')\n",
      "tensor(47278, device='cuda:0') tensor(44739, device='cuda:0')\n",
      "tensor(47503, device='cuda:0') tensor(44953, device='cuda:0')\n",
      "tensor(47721, device='cuda:0') tensor(45159, device='cuda:0')\n",
      "tensor(47938, device='cuda:0') tensor(45361, device='cuda:0')\n",
      "tensor(48160, device='cuda:0') tensor(45567, device='cuda:0')\n",
      "tensor(48373, device='cuda:0') tensor(45772, device='cuda:0')\n",
      "tensor(48596, device='cuda:0') tensor(45988, device='cuda:0')\n",
      "tensor(48815, device='cuda:0') tensor(46201, device='cuda:0')\n",
      "tensor(49038, device='cuda:0') tensor(46410, device='cuda:0')\n",
      "tensor(49264, device='cuda:0') tensor(46626, device='cuda:0')\n",
      "tensor(49485, device='cuda:0') tensor(46835, device='cuda:0')\n",
      "tensor(49705, device='cuda:0') tensor(47038, device='cuda:0')\n",
      "tensor(49937, device='cuda:0') tensor(47259, device='cuda:0')\n",
      "tensor(50157, device='cuda:0') tensor(47467, device='cuda:0')\n",
      "tensor(50371, device='cuda:0') tensor(47671, device='cuda:0')\n",
      "tensor(50595, device='cuda:0') tensor(47880, device='cuda:0')\n",
      "tensor(50823, device='cuda:0') tensor(48096, device='cuda:0')\n",
      "tensor(51045, device='cuda:0') tensor(48308, device='cuda:0')\n",
      "tensor(51271, device='cuda:0') tensor(48522, device='cuda:0')\n",
      "tensor(51495, device='cuda:0') tensor(48738, device='cuda:0')\n",
      "tensor(51721, device='cuda:0') tensor(48950, device='cuda:0')\n",
      "tensor(51948, device='cuda:0') tensor(49164, device='cuda:0')\n",
      "tensor(52172, device='cuda:0') tensor(49380, device='cuda:0')\n",
      "tensor(52394, device='cuda:0') tensor(49589, device='cuda:0')\n",
      "tensor(52613, device='cuda:0') tensor(49797, device='cuda:0')\n",
      "tensor(52839, device='cuda:0') tensor(50006, device='cuda:0')\n",
      "tensor(53062, device='cuda:0') tensor(50216, device='cuda:0')\n",
      "tensor(53278, device='cuda:0') tensor(50418, device='cuda:0')\n",
      "tensor(53493, device='cuda:0') tensor(50622, device='cuda:0')\n",
      "tensor(53715, device='cuda:0') tensor(50836, device='cuda:0')\n",
      "tensor(53949, device='cuda:0') tensor(51060, device='cuda:0')\n",
      "tensor(54164, device='cuda:0') tensor(51258, device='cuda:0')\n",
      "tensor(54381, device='cuda:0') tensor(51463, device='cuda:0')\n",
      "tensor(54606, device='cuda:0') tensor(51679, device='cuda:0')\n",
      "tensor(54829, device='cuda:0') tensor(51889, device='cuda:0')\n",
      "tensor(55049, device='cuda:0') tensor(52101, device='cuda:0')\n",
      "tensor(55267, device='cuda:0') tensor(52300, device='cuda:0')\n",
      "tensor(55494, device='cuda:0') tensor(52515, device='cuda:0')\n",
      "tensor(55587, device='cuda:0') tensor(52604, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w_acc = 0\n",
    "n_acc = 0\n",
    "with torch.no_grad():\n",
    "    for img, target in val_loader:\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        output1 = model1(img.cuda(non_blocking=True))\n",
    "        output2 = model2(img.cuda(non_blocking=True))\n",
    "        output3 = model3(img.cuda(non_blocking=True))\n",
    "        preds = torch.stack([output1,output2,output3])\n",
    "#         print(preds.shape)\n",
    "        _, all_preds = preds.max(-1)\n",
    "#         pred_exist = (all_preds == target)\n",
    "#         print(pred_exist.shape)\n",
    "        label_matrix = (all_preds == target).float().T\n",
    "        logit = label_matrix.T.unsqueeze(2).repeat(1,1,1000) * preds.softmax(dim=-1)\n",
    "        weighted_ensem = logit.sum(dim=0)\n",
    "        naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "        _, w_ensem_pred = weighted_ensem.max(-1)\n",
    "        _, n_ensem_pred = naive_ensem.max(-1)\n",
    "        \n",
    "        w_acc += (w_ensem_pred == target).sum()\n",
    "        n_acc += (n_ensem_pred == target).sum()\n",
    "print(w_acc/len(val_dataset), n_acc/len(val_dataset))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "anonymous-energy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8671648310505132"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55587/len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "proprietary-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8206296215406695"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52604/len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "departmental-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empty-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1059, device='cuda:0') tensor(1.0446, device='cuda:0')\n",
      "tensor(1.0170, device='cuda:0') tensor(1.0232, device='cuda:0') tensor(1.0071, device='cuda:0')\n",
      "79.32981809882871 79.80718230010976 78.5560512915851\n"
     ]
    }
   ],
   "source": [
    "w_acc = 0\n",
    "n_acc = 0\n",
    "acc1 = 0\n",
    "acc2 = 0\n",
    "acc3 = 0\n",
    "m1 = AverageMeter('m1')\n",
    "m2 = AverageMeter('m2')\n",
    "m3 = AverageMeter('m3')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, target in val_loader:\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        output1 = model1(img.cuda(non_blocking=True))\n",
    "        output2 = model2(img.cuda(non_blocking=True))\n",
    "        output3 = model3(img.cuda(non_blocking=True))\n",
    "        preds = torch.stack([output1,output2,output3])\n",
    "        _, p1 = output1.max(-1)\n",
    "        _, p2 = output2.max(-1)\n",
    "        _, p3 = output3.max(-1)\n",
    "        \n",
    "        acc1 += (p1 == target).sum()\n",
    "        acc2 += (p2 == target).sum()\n",
    "        acc3 += (p3 == target).sum()\n",
    "        acc_1, acc_5 = accuracy(output1, target, topk=(1, 5))\n",
    "        m1.update(acc_1.item(),img.size(0))\n",
    "        \n",
    "#         print(acc_1.item(), (p1 == target).sum().item()/len(target))\n",
    "        acc_1, acc_5 = accuracy(output2, target, topk=(1, 5))\n",
    "        m2.update(acc_1.item(),img.size(0))\n",
    "    \n",
    "#         print(acc_1.item(), (p2 == target).sum().item()/len(target))\n",
    "        acc_1, acc_5 = accuracy(output3, target, topk=(1, 5))\n",
    "        m3.update(acc_1.item(),img.size(0))\n",
    "    \n",
    "#         print(acc_1.item(), (p3 == target).sum().item()/len(target))\n",
    "        _, all_preds = preds.max(-1)\n",
    "#         pred_exist = (all_preds == target)\n",
    "#         print(pred_exist.shape)\n",
    "        label_matrix = (all_preds == target).float().T\n",
    "        logit = label_matrix.T.unsqueeze(2).repeat(1,1,1000) * preds.softmax(dim=-1)\n",
    "        weighted_ensem = logit.sum(dim=0)\n",
    "        naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "        _, w_ensem_pred = weighted_ensem.max(-1)\n",
    "        _, n_ensem_pred = naive_ensem.max(-1)\n",
    "        \n",
    "        w_acc += (w_ensem_pred == target).sum()\n",
    "        n_acc += (n_ensem_pred == target).sum()\n",
    "print(w_acc/len(test_dataset), n_acc/len(test_dataset))\n",
    "print(acc1/len(test_dataset), acc2/len(test_dataset), acc3/len(test_dataset))\n",
    "print(m1.avg,m2.avg,m3.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coordinate-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8626, device='cuda:0') tensor(0.8148, device='cuda:0')\n",
      "tensor(0.7933, device='cuda:0') tensor(0.7981, device='cuda:0') tensor(0.7856, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(w_acc/len(val_dataset), n_acc/len(val_dataset))\n",
    "print(acc1/len(val_dataset), acc2/len(val_dataset), acc3/len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thirty-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    ToTensor()\n",
       "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "partial-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import EnsembleSSL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "meaningful-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized EnsembleSSL2\n",
      "loading sep weights\n",
      "missing keys []\n",
      "unexpected keys []\n",
      "missing keys []\n",
      "unexpected keys []\n",
      "missing keys []\n",
      "unexpected keys []\n"
     ]
    }
   ],
   "source": [
    "com_model = EnsembleSSL2('resnet50', 3, 1000, 'freeze').cuda()\n",
    "pt_paths = [\"./dist_models/ft95perc_baseR_cos_lr0.003_bs256/checkpoint_best.pth\",\"./dist_models/ft95perc_eqR_cos_lr0.003_bs256/checkpoint_best.pth\",\"./dist_models/ft95perc_inv_cos_lr0.003_bs256/checkpoint_best.pth\"]\n",
    "com_model.load_sep_weights(pt_paths)\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_baseR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model1.load_state_dict(ckpt)\n",
    "model1.eval()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_eqR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model2.load_state_dict(ckpt)\n",
    "model2.eval()\n",
    "\n",
    "sd = torch.load(\"./dist_models/ft95perc_inv_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "model3.load_state_dict(ckpt)\n",
    "model3.eval()\n",
    "model1=model1.cuda()\n",
    "model2=model2.cuda()\n",
    "model3=model3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "changed-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "tensor(0.8437, device='cuda:0') tensor(0.7916, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w_acc = 0\n",
    "n_acc = 0\n",
    "com_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (img, target) in enumerate(test_loader):\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        output1 = model1(img.cuda(non_blocking=True))\n",
    "        output2 = model2(img.cuda(non_blocking=True))\n",
    "        output3 = model3(img.cuda(non_blocking=True))\n",
    "        preds1 = torch.stack([output1,output2,output3])\n",
    "        preds = com_model.forward(img.cuda(non_blocking=True))\n",
    "        _, all_preds = preds.max(-1)\n",
    "        _, all_preds1 = preds1.max(-1)\n",
    "#         print(preds1[:,0])\n",
    "#         print(preds[:,0])\n",
    "        assert(torch.equal(preds1,preds))\n",
    "        \n",
    "        label_matrix = (all_preds == target).float().T\n",
    "        logit = label_matrix.T.unsqueeze(2).repeat(1,1,1000) * preds.softmax(dim=-1)\n",
    "        weighted_ensem = logit.sum(dim=0)\n",
    "        naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "        _, w_ensem_pred = weighted_ensem.max(-1)\n",
    "        _, n_ensem_pred = naive_ensem.max(-1)\n",
    "        \n",
    "        w_acc += (w_ensem_pred == target).sum()\n",
    "        n_acc += (n_ensem_pred == target).sum()\n",
    "print(w_acc/len(test_dataset), n_acc/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "capital-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'resnet18': models.resnet18,\n",
    "    'resnet50': models.resnet50,\n",
    "}\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from utils import consume_prefix_in_state_dict_if_present\n",
    "\n",
    "class EnsembleSSL2(nn.Module):\n",
    "    def __init__(self, arch, num_ensem=1, num_classes=1000, eval_mode='freeze'):\n",
    "        super().__init__()\n",
    "        print(\"initialized EnsembleSSL2\")\n",
    "        self.num_ensem = num_ensem\n",
    "        self.num_classes = num_classes\n",
    "        model_fn = models_dict[arch]\n",
    "        self.members = torch.nn.ModuleList([model_fn(num_classes=self.num_classes) for _ in range(num_ensem)])\n",
    "        self.set_eval_mode(eval_mode)\n",
    "\n",
    "    def load_sep_weights(self, weights_path_list):\n",
    "        print(\"loading sep weights\")\n",
    "        for m in range(self.num_ensem):\n",
    "            weights = weights_path_list[m]\n",
    "            state_dict = torch.load(weights, map_location='cpu')\n",
    "\n",
    "            cur_mem = self.members[m]\n",
    "            if 'model' in state_dict:\n",
    "                if 'members.0.fc.weight' in state_dict['model']:\n",
    "                    # for LP on imagenet-100 using imagenet ckpt (i.e. different num classes)\n",
    "                    if state_dict['model']['members.0.fc.weight'].shape[0] != self.num_classes:\n",
    "                        print(f\"model weights dim: {state_dict['model']['members.0.fc.weight'].shape[0]}, num classes: {self.num_classes}\")\n",
    "                        new_state_dict = {k:v for k,v in state_dict['model'].items() if 'fc' not in k}\n",
    "                    else:\n",
    "                        new_state_dict = state_dict['model']\n",
    "                    consume_prefix_in_state_dict_if_present(new_state_dict, 'members.0.') # this is assuming only 1 member was trained at a time\n",
    "                    missing_keys, unexpected_keys = cur_mem.load_state_dict(new_state_dict, strict=False)\n",
    "                    print('missing keys', missing_keys)\n",
    "                    print('unexpected keys', unexpected_keys)\n",
    "\n",
    "                else:\n",
    "                    consume_prefix_in_state_dict_if_present(state_dict['model'], 'members.0.') # this is assuming only 1 member was trained at a time\n",
    "                    consume_prefix_in_state_dict_if_present(state_dict['model'], 'module.backbone.')\n",
    "                    missing_keys, unexpected_keys = cur_mem.load_state_dict(state_dict['model'], strict=False)\n",
    "                    print('missing keys', missing_keys)\n",
    "                    print('unexpected keys', unexpected_keys)\n",
    "                    print(\"===> Loaded backbone state dict from \", weights)\n",
    "\n",
    "            elif 'backbone' in state_dict:\n",
    "                missing_keys, unexpected_keys = cur_mem.load_state_dict(state_dict[\"backbone\"], strict=False)\n",
    "                print('missing keys', missing_keys)\n",
    "                print('unexpected keys', unexpected_keys)\n",
    "            else:\n",
    "                print(state_dict.keys())\n",
    "\n",
    "            if 'log_reg_weight' in state_dict and 'log_reg_bias' in state_dict:\n",
    "                cur_mem.fc.weight = torch.from_numpy(state_dict['log_reg_weight'])\n",
    "                cur_mem.fc.bias = torch.from_numpy(state_dict['log_reg_bias'])\n",
    "\n",
    "\n",
    "    def load_weights(self, weights_path_list, convert_from_single=False):\n",
    "        # convert_from_single: whether to convert the weights from 1 model (MultiBackbone)\n",
    "        # making sure that the number of pretrained weights & ensem member size is equal\n",
    "        print(\"loading weights\")\n",
    "        if not convert_from_single:\n",
    "            assert len(self.members) == len(weights_path_list)\n",
    "        else:\n",
    "            assert len(weights_path_list) == 1\n",
    "            ensem_state_dict = torch.load(weights_path_list[0], map_location='cpu')\n",
    "            # ensem_state_dict = ensem_state_dict['enc_state_dict']\n",
    "            state_dicts = convert_weights_from_single_backbone(ensem_state_dict, self.num_ensem)\n",
    "\n",
    "        for m in range(self.num_ensem):\n",
    "            cur_mem = self.members[m]\n",
    "\n",
    "            if convert_from_single:\n",
    "                weights = ''\n",
    "                state_dict = state_dicts[m]\n",
    "            else:\n",
    "                weights = weights_path_list[m]\n",
    "                state_dict = torch.load(weights, map_location='cpu')\n",
    "\n",
    "            if 'epoch' in str(weights):\n",
    "                consume_prefix_in_state_dict_if_present(state_dict['model'], 'module.backbone.')\n",
    "                cur_mem.load_state_dict(state_dict['model'], strict=False)\n",
    "            elif 'simsiam' in str(weights):\n",
    "                consume_prefix_in_state_dict_if_present(state_dict['state_dict'], 'module.backbone.')\n",
    "                consume_prefix_in_state_dict_if_present(state_dict['state_dict'], 'backbone.')\n",
    "                missing_keys, unexpected_keys = cur_mem.load_state_dict(state_dict[\"state_dict\"], strict=False)\n",
    "                print('missing keys', missing_keys)\n",
    "                print('unexpected keys', unexpected_keys)\n",
    "            else:\n",
    "                if 'model' in state_dict:\n",
    "                    missing_keys, unexpected_keys = cur_mem.load_state_dict(state_dict[\"model\"], strict=False)\n",
    "                elif 'backbone' in state_dict:\n",
    "                    missing_keys, unexpected_keys = cur_mem.load_state_dict(state_dict[\"backbone\"], strict=False)\n",
    "                print('missing keys', missing_keys)\n",
    "                print('unexpected keys', unexpected_keys)\n",
    "                # assert missing_keys == ['fc.weight', 'fc.bias'] and unexpected_keys == []\n",
    "\n",
    "            if self.eval_mode in {'linear_probe', 'finetune'}:\n",
    "                cur_mem.fc.weight.data.normal_(mean=0.0, std=0.01)\n",
    "                cur_mem.fc.bias.data.zero_()\n",
    "\n",
    "    def set_eval_mode(self, mode='freeze'):\n",
    "        self.eval_mode = mode\n",
    "        if self.eval_mode == 'freeze':\n",
    "            for cur_mem in self.members:\n",
    "                cur_mem.requires_grad_(False)\n",
    "                cur_mem.fc.requires_grad_(False)\n",
    "        elif self.eval_mode == 'linear_probe':\n",
    "            for cur_mem in self.members:\n",
    "                cur_mem.requires_grad_(False)\n",
    "                cur_mem.fc.requires_grad_(True)\n",
    "        elif self.eval_mode == 'finetune':\n",
    "            for cur_mem in self.members:\n",
    "                cur_mem.requires_grad_(True)\n",
    "                cur_mem.fc.requires_grad_(True)\n",
    "        elif self.eval_mode == 'log_reg':\n",
    "            for cur_mem in self.members:\n",
    "                cur_mem.fc = nn.Identity()\n",
    "                cur_mem.requires_grad_(False)\n",
    "                cur_mem.fc.requires_grad_(False)\n",
    "        elif self.eval_mode == 'extract_features':\n",
    "            for cur_mem in self.members:\n",
    "                # replacing all members' fc layers with identity to extract features\n",
    "                cur_mem.fc = nn.Identity()\n",
    "\n",
    "                cur_mem.requires_grad_(False)\n",
    "                cur_mem.fc.requires_grad_(False)\n",
    "        else:\n",
    "            raise NotImplementedError(f'Evaluation mode {mode} not implemented')\n",
    "\n",
    "\n",
    "    # forward that feeds inputs to the ensemble and returns stacked outputs\n",
    "    def forward(self, x, gate_cond=None):\n",
    "        outputs = []\n",
    "\n",
    "        for cur_mem in self.members:\n",
    "            output = cur_mem(x)\n",
    "            outputs.append(output)\n",
    "\n",
    "        return torch.stack(outputs)\n",
    "\n",
    "    # forward that feeds inputs to the ensemble and returns only the averaged outputs from the ensemble\n",
    "    def forward_ensem(self, x):\n",
    "        outputs = self.forward(x)\n",
    "\n",
    "        return outputs.softmax(dim=-1).mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-eleven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
