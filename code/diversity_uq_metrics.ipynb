{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efficient-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from datasets import Split_Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('/gpfs/u/locker/200/CADS/datasets/ImageNet/val', transform=val_transforms)\n",
    "\n",
    "val_dataset = Split_Dataset('/gpfs/u/locker/200/CADS/datasets/ImageNet',  \\\n",
    "                    f'./calib_splits/am_imagenet_5percent_val.txt',\n",
    "                    transform=val_transforms)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "continued-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = models.resnet50().cuda()\n",
    "# model2 = models.resnet50().cuda()\n",
    "# model3 = models.resnet50().cuda()\n",
    "\n",
    "# sd = torch.load(\"./dist_models/ft95perc_baseR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "# ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "# model1.load_state_dict(ckpt)\n",
    "# model1.eval()\n",
    "\n",
    "# sd = torch.load(\"./dist_models/ft95perc_eqR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "# ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "# model2.load_state_dict(ckpt)\n",
    "# model2.eval()\n",
    "\n",
    "# sd = torch.load(\"./dist_models/ft95perc_inv_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "# ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "# model3.load_state_dict(ckpt)\n",
    "# model3.eval()\n",
    "\n",
    "# gate = models.resnet18(num_classes=3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eastern-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEI\n",
    "def load_3_models(ensem='BEI'):\n",
    "    model1 = models.resnet50().cuda()\n",
    "    model2 = models.resnet50().cuda()\n",
    "    model3 = models.resnet50().cuda()\n",
    "    if ensem == 'BEI':\n",
    "\n",
    "        sd = torch.load(\"./dist_models/ft_baseR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "        ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "        model1.load_state_dict(ckpt)\n",
    "        \n",
    "        sd = torch.load(\"./dist_models/ft_eqR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "        ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "        model2.load_state_dict(ckpt)\n",
    "        \n",
    "        sd = torch.load(\"./dist_models/ft_inv_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "        ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "        model3.load_state_dict(ckpt)\n",
    "        print(\"loaded BEI\")\n",
    "        \n",
    "    elif ensem == 'EEE':\n",
    "        sd = torch.load(\"./dist_models/ft_eqR_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "        ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "        model1.load_state_dict(ckpt)\n",
    "        \n",
    "        sd = torch.load(\"./dist_models/ft_eq69_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "        ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "        model2.load_state_dict(ckpt)\n",
    "        \n",
    "        sd = torch.load(\"./dist_models/ft_eq42_cos_lr0.003_bs256/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "        ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "        model3.load_state_dict(ckpt)\n",
    "        print(\"loaded EEE\")\n",
    "        \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "    return model1, model2, model3\n",
    "\n",
    "def load_1_model(ckpt_path, full_path=False):\n",
    "    model1 = models.resnet50().cuda()\n",
    "    if not full_path:\n",
    "        sd = torch.load(f\"./dist_models/{ckpt_path}/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "    else:\n",
    "        sd = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "    model1.load_state_dict(ckpt)\n",
    "    print(f\"loaded {ckpt_path}\")\n",
    "    model1.eval()\n",
    "    return model1\n",
    "\n",
    "def load_1_ts_model(ckpt_path, full_path=True):\n",
    "    model1 = models.resnet50().cuda()\n",
    "    model1.temp = torch.nn.Parameter(torch.ones(1) * 1.5)\n",
    "    if not full_path:\n",
    "        sd = torch.load(f\"./dist_models/{ckpt_path}/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "    else:\n",
    "        sd = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "    model1.load_state_dict(ckpt)\n",
    "    print(f\"loaded {ckpt_path}\")\n",
    "    model1.eval()\n",
    "    return model1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bigger-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class JSD(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JSD, self).__init__()\n",
    "        self.kl = torch.nn.KLDivLoss(reduction='sum', log_target=True)\n",
    "\n",
    "    def forward(self, p: torch.tensor, q: torch.tensor):\n",
    "        p = F.log_softmax(p, dim=-1)\n",
    "        q = F.log_softmax(q, dim=-1)\n",
    "        \n",
    "        p, q = p.view(-1, p.size(-1)), q.view(-1, q.size(-1))\n",
    "        m = (0.5 * (p + q)).log()\n",
    "        return 0.5 * (self.kl(m, p.log()) + self.kl(m, q.log()))\n",
    "\n",
    "class KLD(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLD, self).__init__()\n",
    "        self.kl = torch.nn.KLDivLoss(reduction='sum', log_target=True)\n",
    "\n",
    "    def forward(self, p: torch.tensor, q: torch.tensor):\n",
    "        p = F.log_softmax(p, dim=-1)\n",
    "        q = F.log_softmax(q, dim=-1)\n",
    "        return self.kl(p,q)\n",
    "\n",
    "kl_div = KLD()\n",
    "js_div = JSD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "empty-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ECELoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_bins=20):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, softmaxes, labels):\n",
    "#         softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1, device=softmaxes.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece\n",
    "\n",
    "nll_criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "ece_criterion = _ECELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "laden-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded EEE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d7df3ae5d2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mkld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdag_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdag_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pair_consensus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mag_p\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdag_p\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ensem = 'EEE'\n",
    "\n",
    "# model1, model2, model3 = load_3_models(ensem=ensem)\n",
    "# def compute_pair_consensus(pair_preds):\n",
    "#     agree = (pair_preds[0] == pair_preds[1])\n",
    "#     agree_correct = agree & (pair_preds[0] == target)\n",
    "#     agree_wrong = agree & (pair_preds[0] != target)\n",
    "#     disagree = (pair_preds[0] != pair_preds[1])\n",
    "#     disagree_both_wrong = disagree & (pair_preds[0] != target) & (pair_preds[1] != target)\n",
    "#     disagree_one_correct = disagree & (pair_preds[0] != target) & (pair_preds[1] == target) \n",
    "#     disagree_one_correct2 = disagree & (pair_preds[1] != target) & (pair_preds[0] == target) \n",
    "#     return agree.sum(), disagree.sum(), agree_correct.sum(), agree_wrong.sum(), disagree_both_wrong.sum(), disagree_one_correct.sum()+disagree_one_correct2.sum()\n",
    "\n",
    "# w_acc = 0\n",
    "# n_acc = 0\n",
    "# ag_sum = 0\n",
    "# ag_c_sum = 0\n",
    "# ag_w_sum = 0\n",
    "# dag_sum = 0\n",
    "# dag_c_sum = 0\n",
    "# dag_w_sum = 0\n",
    "# avg_std_logits = 0.\n",
    "# avg_std = 0.\n",
    "\n",
    "# kld_sum = 0.\n",
    "# # js_div = 0.\n",
    "\n",
    "# ece_ensem, ece1, ece2, ece3 = 0., 0., 0., 0.\n",
    "# nll_ensem, nll1, nll2, nll3 = 0., 0., 0., 0.\n",
    "\n",
    "# pairs = ([0,1], [0,2], [1,2])\n",
    "# targets = []\n",
    "# for it, (img,target) in enumerate(test_loader):\n",
    "#     target = target.cuda(non_blocking=True)\n",
    "#     img = img.cuda(non_blocking=True)\n",
    "#     with torch.no_grad():\n",
    "#         output1 = model1(img)\n",
    "#         output2 = model2(img)\n",
    "#         output3 = model3(img)\n",
    "#         preds = torch.stack([output1,output2,output3])\n",
    "#         avg_std_logits += torch.std(preds, dim=0).mean(dim=-1).sum() # std over members, mean over classes, sum over samples (mean taken later))\n",
    "#         avg_std += torch.std(preds.softmax(-1), dim=0).mean(dim=-1).sum() # std over members, mean over classes, sum over samples (mean taken later))\n",
    "#         _, all_preds = preds.max(-1)\n",
    "#         ag_p, dag_p, ag_c_p, ag_w_p, dag_w_p, dag_c_p = 0, 0, 0, 0, 0, 0\n",
    "#         kld = 0.\n",
    "#         for p in pairs:\n",
    "#             ag, dag, ag_c, ag_w, dag_w, dag_c = compute_pair_consensus(all_preds[p,:])\n",
    "#             ag_p += ag\n",
    "#             dag_p += dag\n",
    "#             ag_c_p += ag_c\n",
    "#             ag_w_p += ag_w\n",
    "#             dag_c_p += dag_c\n",
    "#             dag_w_p += dag_w\n",
    "#             kld += kl_div(preds[p[0]], preds[p[1]])\n",
    "        \n",
    "#         ag_sum += ag_p/len(pairs)\n",
    "#         dag_sum += dag_p/len(pairs)\n",
    "#         ag_c_sum += ag_c_p/len(pairs)\n",
    "#         ag_w_sum += ag_w_p/len(pairs)\n",
    "#         dag_c_sum += dag_c_p/len(pairs)\n",
    "#         dag_w_sum += dag_w_p/len(pairs)\n",
    "#         kld_sum += kld/len(pairs)\n",
    "        \n",
    "#         label_matrix = (all_preds == target).float().T\n",
    "#         logit = label_matrix.T.unsqueeze(2).repeat(1,1,1000) * preds.softmax(dim=-1)\n",
    "#         weighted_ensem = logit.sum(dim=0)\n",
    "#         naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "#         _, w_ensem_pred = weighted_ensem.max(-1)\n",
    "#         _, n_ensem_pred = naive_ensem.max(-1)\n",
    "#         w_acc += (w_ensem_pred == target).sum()\n",
    "#         n_acc += (n_ensem_pred == target).sum()\n",
    "        \n",
    "#         ece1 += ece_criterion(output1.softmax(-1), target)\n",
    "        \n",
    "#     targets.append(label_matrix)\n",
    "# print(f\"UB: {w_acc/len(test_dataset)} | ensem: {n_acc/len(test_dataset)}\")\n",
    "# print(f\"agree: {ag_sum/len(test_dataset)} | disagree: {dag_sum/len(test_dataset)}\") \n",
    "# print(f\"agree_correct: {ag_c_sum/len(test_dataset)} | agree_wrong: {ag_w_sum/len(test_dataset)}\") \n",
    "# print(f\"disagree_1correct: {dag_c_sum/len(test_dataset)} | disagree_2wrong: {dag_w_sum/len(test_dataset)}\") \n",
    "# print(f\"Ensemble Variance Logits: {avg_std_logits/len(test_dataset)}\") \n",
    "# print(f\"Ensemble Variance: {avg_std/len(test_dataset)}\") \n",
    "# print(f\"KL div: {kld_sum/len(test_dataset)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "latest-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pair_consensus(pair_preds):\n",
    "    agree = (pair_preds[0] == pair_preds[1])\n",
    "    agree_correct = agree & (pair_preds[0] == target)\n",
    "    agree_wrong = agree & (pair_preds[0] != target)\n",
    "    disagree = (pair_preds[0] != pair_preds[1])\n",
    "    disagree_both_wrong = disagree & (pair_preds[0] != target) & (pair_preds[1] != target)\n",
    "    disagree_one_correct = disagree & (pair_preds[0] != target) & (pair_preds[1] == target) \n",
    "    disagree_one_correct2 = disagree & (pair_preds[1] != target) & (pair_preds[0] == target) \n",
    "    return agree.sum(), disagree.sum(), agree_correct.sum(), agree_wrong.sum(), disagree_both_wrong.sum(), disagree_one_correct.sum()+disagree_one_correct2.sum()\n",
    "\n",
    "def get_div_metrics(output1,output2,output3):\n",
    "    preds = torch.stack([output1,output2,output3])\n",
    "    avg_std_logits = torch.std(preds, dim=0).mean(dim=-1).mean() # std over members, mean over classes, sum over samples (mean taken later))\n",
    "    avg_std = torch.std(preds.softmax(-1), dim=0).mean(dim=-1).mean() # std over members, mean over classes, sum over samples (mean taken later))\n",
    "    _, all_preds = preds.max(-1)\n",
    "    ag_p, dag_p, ag_c_p, ag_w_p, dag_w_p, dag_c_p = 0, 0, 0, 0, 0, 0\n",
    "    kld = 0.\n",
    "    for p in pairs:\n",
    "        ag, dag, ag_c, ag_w, dag_w, dag_c = compute_pair_consensus(all_preds[p,:])\n",
    "        ag_p += ag\n",
    "        dag_p += dag\n",
    "        ag_c_p += ag_c\n",
    "        ag_w_p += ag_w\n",
    "        dag_c_p += dag_c\n",
    "        dag_w_p += dag_w\n",
    "        kld += kl_div(preds[p[0]], preds[p[1]])\n",
    "\n",
    "    ag_sum = ag_p/len(pairs)\n",
    "    dag_sum = dag_p/len(pairs)\n",
    "    ag_c_sum = ag_c_p/len(pairs)\n",
    "    ag_w_sum = ag_w_p/len(pairs)\n",
    "    dag_c_sum = dag_c_p/len(pairs)\n",
    "    dag_w_sum = dag_w_p/len(pairs)\n",
    "    kld_sum = kld/len(pairs)\n",
    "    return ag_sum/len(output1), dag_sum/len(output1), ag_c_sum/len(output1), ag_w_sum/len(output1), dag_c_sum/len(output1), dag_w_sum/len(output1), kld_sum/len(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wound-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ECELoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(_ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, softmaxes, labels):\n",
    "#         softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1, device=softmaxes.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece\n",
    "# loss = F.nll_loss(torch.log(probs[mask] + epsilon), target[mask])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "graphic-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_loader(model, loader):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for it, (img, target) in enumerate(loader):\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        img = img.cuda(non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            output1 = model(img)\n",
    "#             ece_1 = ece_criterion(output1.softmax(-1), target)\n",
    "            targets.append(target)\n",
    "            outputs.append(output1)\n",
    "    return torch.cat(outputs), torch.cat(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tight-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded BEI\n",
      "loaded EEE\n"
     ]
    }
   ],
   "source": [
    "# model1, model2, model3 = load_models(ensem='BEI')\n",
    "# model4, model5, model6 = load_models(ensem='EEE')\n",
    "\n",
    "# out1, tar1 = rollout_loader(model1, test_loader2)\n",
    "# out2, tar2 = rollout_loader(model2, test_loader2)\n",
    "# out3, tar3 = rollout_loader(model3, test_loader2)\n",
    "\n",
    "\n",
    "# out4, tar4 = rollout_loader(model4, test_loader2)\n",
    "# out5, tar5 = rollout_loader(model5, test_loader2)\n",
    "# out6, tar6 = rollout_loader(model6, test_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "basic-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import inspect\n",
    "from netcal.metrics import ECE\n",
    "\n",
    "cecriterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "nll_criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "ece_criterion = _ECELoss().cuda()\n",
    "ece_netcal = ECE(15)\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "\n",
    "def retrieve_name(var):\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
    "\n",
    "\n",
    "def get_metrics(outs, tars, names, printing=True):\n",
    "    for out, tar,name in zip(outs,tars,names):\n",
    "        ece1 = ece_netcal.measure(out.softmax(-1).cpu().numpy(), tar.cpu().numpy())\n",
    "        ece2 = ece_criterion(out.softmax(-1), tar)\n",
    "        loss = F.nll_loss(torch.log(out.softmax(-1)), tar)\n",
    "        loss2 = cecriterion(out, tar)\n",
    "        _, pred = out.max(-1)\n",
    "        acc = ((pred == tar).sum()) / len(tar)\n",
    "        if printing:\n",
    "            print(name)\n",
    "            print(\"NLL:\", loss.item(), loss2.item())\n",
    "            print(\"ECE:\", ece1, ece2.item())\n",
    "            print(\"Acc:\", acc.item())\n",
    "    return loss.item(), ece2.item(), acc.item()\n",
    "\n",
    "def get_metrics_softmax(outs, tars, names, printing=True):\n",
    "    for out, tar, name in zip(outs,tars,names):\n",
    "        ece1 = ece_netcal.measure(out.cpu().numpy(), tar.cpu().numpy())\n",
    "        ece2 = ece_criterion(out, tar)\n",
    "        loss = F.nll_loss(torch.log(out), tar)\n",
    "        _, pred = out.max(-1)\n",
    "        acc = ((pred == tar).sum()) / len(tar)\n",
    "        if printing:\n",
    "            print(name)\n",
    "            print(\"NLL:\", loss.item())\n",
    "            print(\"ECE:\", ece1, ece2.item())\n",
    "            print(\"Acc:\", acc.item())\n",
    "    return loss.item(), ece2.item(), acc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "weird-berkeley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ft_eq69_cos_lr0.003_bs256\n",
      "loaded ft_eq42_cos_lr0.003_bs256\n",
      "loaded ft_eq31_cos_lr0.003_bs256\n",
      "loaded ft_eq24_cos_lr0.003_bs256\n",
      "loaded ft_baseR_cos_lr0.003_bs256\n",
      "loaded ft_base31_cos_lr0.003_bs256\n",
      "loaded ft_base24_cos_lr0.003_bs256\n",
      "loaded ft_base69_cos_lr0.003_bs256\n",
      "loaded ft_inv_cos_lr0.003_bs256\n",
      "loaded ft_inv24_cos_lr0.004_bs256\n",
      "loaded ft_inv31_cos_lr0.004_bs256\n",
      "loaded ft_inv69_cos_lr0.004_bs256\n"
     ]
    }
   ],
   "source": [
    "# eqR = load_1_model(\"ft_eqR_cos_lr0.003_bs256\")\n",
    "# eqR_out, eqR_tar = rollout_loader(eqR, test_loader2)\n",
    "\n",
    "eq69 = load_1_model(\"ft_eq69_cos_lr0.003_bs256\")\n",
    "eq69_out, eq69_tar = rollout_loader(eq69, test_loader2)\n",
    "\n",
    "eq42 = load_1_model(\"ft_eq42_cos_lr0.003_bs256\")\n",
    "eq42_out, eq42_tar = rollout_loader(eq42, test_loader2)\n",
    "\n",
    "eq31 = load_1_model(\"ft_eq31_cos_lr0.003_bs256\")\n",
    "eq31_out, eq31_tar = rollout_loader(eq31, test_loader2)\n",
    "\n",
    "eq24 = load_1_model(\"ft_eq24_cos_lr0.003_bs256\")\n",
    "eq24_out, eq24_tar = rollout_loader(eq24, test_loader2)\n",
    "\n",
    "baseR = load_1_model(\"ft_baseR_cos_lr0.003_bs256\")\n",
    "baseR_out, baseR_tar = rollout_loader(baseR, test_loader2)\n",
    "\n",
    "base31 = load_1_model(\"ft_base31_cos_lr0.003_bs256\")\n",
    "base31_out, base31_tar = rollout_loader(base31, test_loader2)\n",
    "\n",
    "base24 = load_1_model(\"ft_base24_cos_lr0.003_bs256\")\n",
    "base24_out, base24_tar = rollout_loader(base24, test_loader2)\n",
    "\n",
    "base69 = load_1_model(\"ft_base69_cos_lr0.003_bs256\")\n",
    "base69_out, base69_tar = rollout_loader(base69, test_loader2)\n",
    "\n",
    "inv = load_1_model(\"ft_inv_cos_lr0.003_bs256\")\n",
    "inv_out, inv_tar = rollout_loader(inv, test_loader2)\n",
    "\n",
    "inv24 = load_1_model(\"ft_inv24_cos_lr0.004_bs256\")\n",
    "inv24_out, inv24_tar = rollout_loader(inv24, test_loader2)\n",
    "\n",
    "inv31 = load_1_model(\"ft_inv31_cos_lr0.004_bs256\")\n",
    "inv31_out, inv31_tar = rollout_loader(inv31, test_loader2)\n",
    "\n",
    "inv69 = load_1_model(\"ft_inv69_cos_lr0.004_bs256\")\n",
    "inv69_out, inv69_tar = rollout_loader(inv69, test_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vulnerable-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./dist_models/new_eseeds/roteq-IN1k-e800-seed54-ft-cos-lr0.003-bs258-checkpoint_best.pth\n",
      "loaded ./dist_models/new_eseeds/roteq-IN1k-e800-seed96-ft-cos-lr0.003-bs258-checkpoint_best.pth\n"
     ]
    }
   ],
   "source": [
    "eq54 = load_1_model(\"./dist_models/new_eseeds/roteq-IN1k-e800-seed54-ft-cos-lr0.003-bs258-checkpoint_best.pth\", full_path=True)\n",
    "eq54_out, eq54_tar = rollout_loader(eq54, test_loader2)\n",
    "eq96 = load_1_model(\"./dist_models/new_eseeds/roteq-IN1k-e800-seed96-ft-cos-lr0.003-bs258-checkpoint_best.pth\", full_path=True)\n",
    "eq96_out, eq96_tar = rollout_loader(eq96, test_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "biological-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eq69\n",
      "NLL: 0.9093856811523438 0.9093856811523438\n",
      "ECE: 0.033749116531610494 0.03374912589788437\n",
      "Acc: 0.7688199877738953\n",
      "eq42\n",
      "NLL: 0.9061233401298523 0.9061233401298523\n",
      "ECE: 0.030388223373964407 0.030388232320547104\n",
      "Acc: 0.7691799998283386\n",
      "eq31\n",
      "NLL: 0.9056292772293091 0.9056292772293091\n",
      "ECE: 0.03064080397954215 0.03064080700278282\n",
      "Acc: 0.7682399749755859\n",
      "eq24\n",
      "NLL: 0.9061529040336609 0.9061529040336609\n",
      "ECE: 0.03489678953457627 0.03489677608013153\n",
      "Acc: 0.7687000036239624\n",
      "eq96\n",
      "NLL: 0.9118058681488037 0.9118058085441589\n",
      "ECE: 0.015920435016825808 0.015920434147119522\n",
      "Acc: 0.7660799622535706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9118058681488037, 0.015920434147119522, 0.7660799622535706)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eq = [eq69_out, eq42_out, eq31_out, eq24_out, eq96_out]\n",
    "tars = [eq69_tar, eq42_tar, eq31_tar, eq24_tar, eq96_tar]\n",
    "names = ['eq69', 'eq42', 'eq31', 'eq24', 'eq96']\n",
    "get_metrics(all_eq,tars,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "functioning-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseR\n",
      "NLL: 0.9216957688331604 0.9216957092285156\n",
      "ECE: 0.029824816861990854 0.029824834316968918\n",
      "Acc: 0.7664600014686584\n",
      "base31\n",
      "NLL: 0.9237775206565857 0.9237775206565857\n",
      "ECE: 0.03522903372485192 0.035229045897722244\n",
      "Acc: 0.7649199962615967\n",
      "base24\n",
      "NLL: 0.9240396022796631 0.9240396022796631\n",
      "ECE: 0.03593387361943723 0.03593389689922333\n",
      "Acc: 0.7640799880027771\n",
      "base69\n",
      "NLL: 0.9307573437690735 0.9307572841644287\n",
      "ECE: 0.03674560508206489 0.036745600402355194\n",
      "Acc: 0.7646600008010864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9307573437690735, 0.036745600402355194, 0.7646600008010864)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_base = [baseR_out, base31_out, base24_out, base69_out]\n",
    "tars = [baseR_tar, base31_tar, base24_tar, base69_tar]\n",
    "names = ['baseR', 'base31', 'base24', 'base69']\n",
    "get_metrics(all_base,tars, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "permanent-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv\n",
      "NLL: 0.9599096179008484 0.9599095582962036\n",
      "ECE: 0.03850943553138525 0.03850942850112915\n",
      "Acc: 0.7601400017738342\n",
      "inv31\n",
      "NLL: 0.9739280343055725 0.9739281535148621\n",
      "ECE: 0.049294076371714485 0.049294114112854004\n",
      "Acc: 0.7590399980545044\n",
      "inv24\n",
      "NLL: 0.9637317061424255 0.9637317061424255\n",
      "ECE: 0.04837276127699763 0.048372745513916016\n",
      "Acc: 0.7591599822044373\n",
      "inv69\n",
      "NLL: 0.9665408730506897 0.9665408730506897\n",
      "ECE: 0.0469485394675657 0.04694851115345955\n",
      "Acc: 0.7595199942588806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9665408730506897, 0.04694851115345955, 0.7595199942588806)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inv = [inv_out, inv31_out, inv24_out, inv69_out]\n",
    "tars = [inv_tar, inv31_tar, inv24_tar, inv69_tar]\n",
    "names = ['inv', 'inv31', 'inv24', 'inv69']\n",
    "get_metrics(all_inv,tars,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faced-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(torch.equal(eq42_tar, eq69_tar))\n",
    "assert(torch.equal(eq42_tar, eq42_tar))\n",
    "assert(torch.equal(eq42_tar, eq31_tar))\n",
    "assert(torch.equal(eq42_tar, eq24_tar))\n",
    "assert(torch.equal(eq24_tar, baseR_tar))\n",
    "assert(torch.equal(eq42_tar, inv_tar))\n",
    "assert(torch.equal(baseR_tar, base69_tar))\n",
    "assert(torch.equal(baseR_tar, base31_tar))\n",
    "assert(torch.equal(baseR_tar, base24_tar))\n",
    "same_tar = baseR_tar\n",
    "# True since loader shuffle set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "mighty-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eq69\n",
      "NLL: 0.9093856811523438 | ECE: 0.033749116531610494\n",
      "Acc: 0.7688199877738953\n",
      "b69\n",
      "NLL: 0.9307573437690735 | ECE: 0.03674560508206489\n",
      "Acc: 0.7646600008010864\n",
      "inv69\n",
      "NLL: 0.9665408730506897 | ECE: 0.0469485394675657\n",
      "Acc: 0.7595199942588806\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from eval_metrics import get_metrics as get_new_metrics\n",
    "num_classes=1000\n",
    "\n",
    "_,_,_,acc_pc_eq69 = get_new_metrics([eq69_out], [same_tar],['eq69'], num_classes=num_classes)\n",
    "_,_,_,acc_pc_b69 = get_new_metrics([base69_out], [same_tar],['b69'], num_classes=num_classes)\n",
    "_,_,_,acc_pc_inv69 = get_new_metrics([inv69_out], [same_tar],['inv69'], num_classes=num_classes)\n",
    "print('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "controversial-attendance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 eq: tensor(53, device='cuda:0')\n",
      "BE eq: tensor(87, device='cuda:0')\n",
      "EI eq: tensor(59, device='cuda:0')\n",
      "BI eq: tensor(62, device='cuda:0')\n",
      "B best: tensor(224, device='cuda:0')\n",
      "E best: tensor(281, device='cuda:0')\n",
      "I best: tensor(234, device='cuda:0')\n",
      "tensor(1000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "all_3_eq = (acc_pc_eq69 == acc_pc_b69) & (acc_pc_eq69 == acc_pc_inv69)\n",
    "print(\"3 eq:\", all_3_eq.sum())\n",
    "be_eq = (acc_pc_eq69 == acc_pc_b69) & ~all_3_eq & (acc_pc_eq69 > acc_pc_inv69)\n",
    "print(\"BE eq:\", be_eq.sum())\n",
    "ei_eq = (acc_pc_eq69 == acc_pc_inv69) & ~all_3_eq & (acc_pc_eq69 > acc_pc_b69)\n",
    "print(\"EI eq:\",ei_eq.sum())\n",
    "bi_eq = (acc_pc_b69 == acc_pc_inv69) & ~all_3_eq & (acc_pc_b69 > acc_pc_eq69)\n",
    "print(\"BI eq:\", bi_eq.sum())\n",
    "uniq = ~(all_3_eq | be_eq | ei_eq | bi_eq)\n",
    "\n",
    "b_best = (acc_pc_b69 > acc_pc_eq69) & (acc_pc_b69 > acc_pc_inv69)\n",
    "print(\"B best:\", b_best.sum())\n",
    "e_best = (acc_pc_eq69 > acc_pc_b69) & (acc_pc_eq69 > acc_pc_inv69)\n",
    "print(\"E best:\", e_best.sum())\n",
    "i_best = (acc_pc_inv69 > acc_pc_eq69) & (acc_pc_inv69 > acc_pc_b69)\n",
    "print(\"I best:\", i_best.sum())\n",
    "\n",
    "total = all_3_eq.sum() + be_eq.sum() + ei_eq.sum() + bi_eq.sum() + b_best.sum() + e_best.sum() + i_best.sum()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "unable-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000, device='cuda:0')\n",
      "tensor(160, device='cuda:0')\n",
      "tensor(477, device='cuda:0')\n",
      "tensor(363, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# consider 2 models\n",
    "pc1 = acc_pc_eq69\n",
    "pc2 = acc_pc_inv69\n",
    "ei_eq2 = acc_pc_eq69 == acc_pc_inv69\n",
    "e_better_i = acc_pc_eq69 > acc_pc_inv69\n",
    "i_better_e = acc_pc_inv69 > acc_pc_eq69\n",
    "print(ei_eq2.sum()+e_better_i.sum()+i_better_e.sum())\n",
    "print(ei_eq2.sum())\n",
    "print(e_better_i.sum())\n",
    "print(i_better_e.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "removed-lighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.1180, device='cuda:0')\n",
      "tensor(18.3000, device='cuda:0')\n",
      "tensor(16.2580, device='cuda:0')\n",
      "tensor(14.9640, device='cuda:0')\n",
      "tensor(14.1520, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "all_eq = [eq69_out, eq42_out, eq31_out, eq24_out, eq96_out]\n",
    "_, pred = eq69_out.max(-1)\n",
    "correct_vec69 = (pred == same_tar)\n",
    "_, pred = eq42_out.max(-1)\n",
    "correct_vec42 = (pred == same_tar)\n",
    "_, pred = eq31_out.max(-1)\n",
    "correct_vec31 = (pred == same_tar)\n",
    "_, pred = eq24_out.max(-1)\n",
    "correct_vec24 = (pred == same_tar)\n",
    "_, pred = eq96_out.max(-1)\n",
    "correct_vec96 = (pred == same_tar)\n",
    "\n",
    "print((~correct_vec69).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec42).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec42 & ~correct_vec31).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec42 & ~correct_vec31 & ~correct_vec24).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec42 & ~correct_vec31 & ~correct_vec24 & ~correct_vec96).sum()/5e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "textile-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred = inv69_out.max(-1)\n",
    "correct_vec69_i = (pred == same_tar)\n",
    "_, pred = inv31_out.max(-1)\n",
    "correct_vec31_i = (pred == same_tar)\n",
    "_, pred = inv24_out.max(-1)\n",
    "correct_vec24_i = (pred == same_tar)\n",
    "_, pred = inv_out.max(-1)\n",
    "correct_vec_i = (pred == same_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fabulous-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.1180, device='cuda:0')\n",
      "tensor(17.8400, device='cuda:0')\n",
      "tensor(15.6400, device='cuda:0')\n",
      "tensor(14.3860, device='cuda:0')\n",
      "tensor(13.6200, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((~correct_vec69).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec31_i).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec31_i & ~correct_vec31).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec31_i & ~correct_vec31 & ~correct_vec_i).sum()/5e2)\n",
    "print((~correct_vec69 & ~correct_vec31_i & ~correct_vec31 & ~correct_vec_i & ~correct_vec96).sum()/5e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "another-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensem_E(num_models=2, num_comb=5):\n",
    "    ee_nll = []\n",
    "    ee_ece = []\n",
    "    ee_acc = []\n",
    "    for i in range(num_comb):\n",
    "        out_list = np.random.choice(all_eq, num_models, replace=False)\n",
    "        out_list = [torch.Tensor(x.cpu()) for x in out_list]\n",
    "        ee_out = torch.stack(out_list).softmax(-1).mean(dim=0).cuda()\n",
    "        nll, ece, acc, _ = get_new_metrics([ee_out],[same_tar],[f'EE_comb{i}'], printing=False, input_softmax=True)    \n",
    "        ee_nll.append(nll)\n",
    "        ee_ece.append(ece)  \n",
    "        ee_acc.append(acc)\n",
    "    print(\"E\"*num_models)\n",
    "    print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.std(ee_nll):.4f}\")\n",
    "    print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.std(ee_ece):.4f}\")\n",
    "    print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.std(ee_acc):.4f}\")\n",
    "\n",
    "def ensem_BEI(num_E=0, num_B=0, num_I=0, num_comb=5, err='std'):\n",
    "    ee_nll = []\n",
    "    ee_ece = []\n",
    "    ee_acc = []\n",
    "    for i in range(num_comb):\n",
    "        eq_list = np.random.choice(all_eq, num_E, replace=False)\n",
    "        base_list = np.random.choice(all_base, num_B, replace=False)\n",
    "        inv_list = np.random.choice(all_inv, num_I, replace=False)\n",
    "        out_list = list(eq_list) + list(base_list) + list(inv_list)\n",
    "        out_list = [torch.Tensor(x.cpu()) for x in out_list]\n",
    "        ee_out = torch.stack(out_list).softmax(-1).mean(dim=0).cuda()\n",
    "        nll, ece, acc, _ = get_new_metrics([ee_out],[same_tar],[f'EE_comb{i}'], printing=False, input_softmax=True)    \n",
    "        ee_nll.append(nll)\n",
    "        ee_ece.append(ece)  \n",
    "        ee_acc.append(acc)\n",
    "    print(\"E\"*num_E + \"B\"*num_B + \"I\"*num_I)\n",
    "    if err=='std':\n",
    "        print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.std(ee_nll):.4f}\")\n",
    "        print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.std(ee_ece):.4f}\")\n",
    "        print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.std(ee_acc):.4f}\")\n",
    "    elif err=='var':\n",
    "        print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.var(ee_nll):.4f}\")\n",
    "        print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.var(ee_ece):.4f}\")\n",
    "        print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.var(ee_acc):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "developmental-absence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE\n",
      "NLL: 0.8449 +/- 0.0034\n",
      "ECE: 0.0146 +/- 0.0006\n",
      "Acc: 0.7812 +/- 0.0011\n",
      "EEE\n",
      "NLL: 0.8226 +/- 0.0029\n",
      "ECE: 0.0184 +/- 0.0009\n",
      "Acc: 0.7863 +/- 0.0010\n",
      "EEEE\n",
      "NLL: 0.8105 +/- 0.0000\n",
      "ECE: 0.0207 +/- 0.0000\n",
      "Acc: 0.7885 +/- 0.0000\n",
      "EEEEE\n",
      "NLL: 0.8028 +/- 0.0000\n",
      "ECE: 0.0238 +/- 0.0000\n",
      "Acc: 0.7909 +/- 0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    ensem_BEI(num_E=i,num_B=0, num_I=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "included-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "NLL: 0.9067 +/- 0.0014\n",
      "ECE: 0.0320 +/- 0.0019\n",
      "Acc: 0.7688 +/- 0.0003\n"
     ]
    }
   ],
   "source": [
    "# 1 models\n",
    "ensem_BEI(num_E=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "explicit-wallace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE\n",
      "NLL: 0.8433 +/- 0.0037\n",
      "ECE: 0.0146 +/- 0.0009\n",
      "Acc: 0.7821 +/- 0.0012\n",
      "EB\n",
      "NLL: 0.8478 +/- 0.0047\n",
      "ECE: 0.0145 +/- 0.0016\n",
      "Acc: 0.7808 +/- 0.0015\n",
      "EI\n",
      "NLL: 0.8458 +/- 0.0016\n",
      "ECE: 0.0148 +/- 0.0003\n",
      "Acc: 0.7822 +/- 0.0006\n"
     ]
    }
   ],
   "source": [
    "# 2 models\n",
    "ensem_BEI(num_E=2)\n",
    "ensem_BEI(num_E=1, num_B=1)\n",
    "ensem_BEI(num_E=1, num_I=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "naked-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEE\n",
      "NLL: 0.8198 +/- 0.0034\n",
      "ECE: 0.0172 +/- 0.0011\n",
      "Acc: 0.7867 +/- 0.0011\n",
      "EBI\n",
      "NLL: 0.8220 +/- 0.0021\n",
      "ECE: 0.0206 +/- 0.0007\n",
      "Acc: 0.7878 +/- 0.0008\n",
      "EEI\n",
      "NLL: 0.8166 +/- 0.0013\n",
      "ECE: 0.0191 +/- 0.0005\n",
      "Acc: 0.7882 +/- 0.0004\n",
      "EEB\n",
      "NLL: 0.8234 +/- 0.0037\n",
      "ECE: 0.0189 +/- 0.0019\n",
      "Acc: 0.7866 +/- 0.0010\n"
     ]
    }
   ],
   "source": [
    "# 3 models\n",
    "ensem_BEI(num_E=3)\n",
    "ensem_BEI(num_E=1, num_B=1, num_I=1)\n",
    "ensem_BEI(num_E=2, num_I=1)\n",
    "ensem_BEI(num_E=2, num_B=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fixed-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEEE\n",
      "NLL: 0.8086 +/- 0.0025\n",
      "ECE: 0.0214 +/- 0.0006\n",
      "Acc: 0.7897 +/- 0.0011\n",
      "EEBI\n",
      "NLL: 0.8079 +/- 0.0017\n",
      "ECE: 0.0249 +/- 0.0009\n",
      "Acc: 0.7915 +/- 0.0004\n",
      "EEII\n",
      "NLL: 0.8084 +/- 0.0024\n",
      "ECE: 0.0249 +/- 0.0011\n",
      "Acc: 0.7908 +/- 0.0009\n",
      "EEBB\n",
      "NLL: 0.8108 +/- 0.0019\n",
      "ECE: 0.0215 +/- 0.0009\n",
      "Acc: 0.7896 +/- 0.0006\n",
      "EEEI\n",
      "NLL: 0.8050 +/- 0.0035\n",
      "ECE: 0.0240 +/- 0.0014\n",
      "Acc: 0.7907 +/- 0.0005\n",
      "EEEB\n",
      "NLL: 0.8111 +/- 0.0024\n",
      "ECE: 0.0224 +/- 0.0011\n",
      "Acc: 0.7895 +/- 0.0005\n"
     ]
    }
   ],
   "source": [
    "# 4 models\n",
    "ensem_BEI(num_E=4)\n",
    "ensem_BEI(num_E=2, num_B=1, num_I=1)\n",
    "ensem_BEI(num_E=2, num_I=2)\n",
    "ensem_BEI(num_E=2, num_B=2)\n",
    "ensem_BEI(num_E=3, num_I=1)\n",
    "ensem_BEI(num_E=3, num_B=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "heated-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEEEE\n",
      "NLL: 0.8028 +/- 0.0000\n",
      "ECE: 0.0238 +/- 0.0000\n",
      "Acc: 0.7909 +/- 0.0000\n",
      "EEBBI\n",
      "NLL: 0.8031 +/- 0.0028\n",
      "ECE: 0.0262 +/- 0.0010\n",
      "Acc: 0.7916 +/- 0.0012\n",
      "EEBII\n",
      "NLL: 0.7997 +/- 0.0012\n",
      "ECE: 0.0263 +/- 0.0013\n",
      "Acc: 0.7927 +/- 0.0008\n",
      "EEIII\n",
      "NLL: 0.8054 +/- 0.0019\n",
      "ECE: 0.0277 +/- 0.0009\n",
      "Acc: 0.7917 +/- 0.0005\n",
      "EEBBB\n",
      "NLL: 0.8054 +/- 0.0023\n",
      "ECE: 0.0233 +/- 0.0006\n",
      "Acc: 0.7906 +/- 0.0006\n",
      "EEEII\n",
      "NLL: 0.7983 +/- 0.0028\n",
      "ECE: 0.0267 +/- 0.0006\n",
      "Acc: 0.7929 +/- 0.0009\n",
      "EEEBB\n",
      "NLL: 0.8040 +/- 0.0026\n",
      "ECE: 0.0239 +/- 0.0008\n",
      "Acc: 0.7911 +/- 0.0008\n",
      "EEEEI\n",
      "NLL: 0.7986 +/- 0.0020\n",
      "ECE: 0.0261 +/- 0.0007\n",
      "Acc: 0.7920 +/- 0.0006\n",
      "EEEEB\n",
      "NLL: 0.8010 +/- 0.0024\n",
      "ECE: 0.0238 +/- 0.0014\n",
      "Acc: 0.7919 +/- 0.0007\n"
     ]
    }
   ],
   "source": [
    "# 5 models\n",
    "ensem_BEI(num_E=5)\n",
    "ensem_BEI(num_E=2, num_B=2, num_I=1)\n",
    "ensem_BEI(num_E=2, num_B=1, num_I=2)\n",
    "ensem_BEI(num_E=2, num_I=3)\n",
    "ensem_BEI(num_E=2, num_B=3)\n",
    "ensem_BEI(num_E=3, num_I=2)\n",
    "ensem_BEI(num_E=3, num_B=2)\n",
    "ensem_BEI(num_E=4, num_I=1)\n",
    "ensem_BEI(num_E=4, num_B=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "deadly-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BB\n",
      "NLL: 0.8558 +/- 0.0006\n",
      "ECE: 0.0137 +/- 0.0008\n",
      "Acc: 0.7790 +/- 0.0002\n",
      "BBB\n",
      "NLL: 0.8309 +/- 0.0007\n",
      "ECE: 0.0179 +/- 0.0004\n",
      "Acc: 0.7858 +/- 0.0004\n",
      "BBBB\n",
      "NLL: 0.8186 +/- 0.0000\n",
      "ECE: 0.0214 +/- 0.0000\n",
      "Acc: 0.7887 +/- 0.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-b29a59169a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mensem_BEI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_E\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_B\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_I\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-147-7c2b0601872e>\u001b[0m in \u001b[0;36mensem_BEI\u001b[0;34m(num_E, num_B, num_I, num_comb, err)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_comb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0meq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_eq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mbase_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0minv_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "for i in range(2,6):\n",
    "    ensem_BEI(num_E=0,num_B=i, num_I=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "signed-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffea0ad91d0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_E = [76.88, 78.21, 78.67, 78.97, 79.09]\n",
    "all_E_err = [0.03, 0.12, 0.11, 0.11, 0.0]\n",
    "\n",
    "EI = [76.88, 78.22, 78.82, 79.08, 79.29]\n",
    "EI_err = [0.03, 0.06, 0.04, 0.09, 0.09]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "x = np.arange(1,6)\n",
    "plt.errorbar(x,all_E, yerr=all_E_err,label='Eq')\n",
    "plt.errorbar(x,EI, yerr=EI_err,label='Eq + Inv')\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"# of models\")\n",
    "plt.ylabel(\"Ensem. Acc.\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "combined-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEI\n",
      "NLL: 0.8208 +/- 0.0029\n",
      "ECE: 0.0223 +/- 0.0012\n",
      "Acc: 0.7879 +/- 0.0010\n",
      "EII\n",
      "NLL: 0.8287 +/- 0.0033\n",
      "ECE: 0.0202 +/- 0.0012\n",
      "Acc: 0.7857 +/- 0.0012\n",
      "EBI\n",
      "NLL: 0.8199 +/- 0.0012\n",
      "ECE: 0.0203 +/- 0.0008\n",
      "Acc: 0.7879 +/- 0.0001\n"
     ]
    }
   ],
   "source": [
    "# 3 models\n",
    "\n",
    "num_comb = 5\n",
    "\n",
    "ee_nll = []\n",
    "ee_ece = []\n",
    "ee_acc = []\n",
    "for i in range(num_comb):\n",
    "    [eq1, eq3] = np.random.choice(all_eq, 2, replace=False)\n",
    "    [eq2] = np.random.choice(all_inv, 1, replace=False)\n",
    "    ee_out = (eq1.softmax(-1) + eq2.softmax(-1) + eq3.softmax(-1))/3\n",
    "    nll, ece, acc, _ = get_new_metrics([ee_out],[same_tar],[f'EE_comb{i}'], printing=False, input_softmax=True)    \n",
    "    ee_nll.append(nll)\n",
    "    ee_ece.append(ece)  \n",
    "    ee_acc.append(acc)\n",
    "print(\"EEI\")\n",
    "print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.std(ee_nll):.4f}\")\n",
    "print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.std(ee_ece):.4f}\")\n",
    "print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.std(ee_acc):.4f}\")\n",
    "\n",
    "ee_nll = []\n",
    "ee_ece = []\n",
    "ee_acc = []\n",
    "for i in range(num_comb):\n",
    "    [eq1] = np.random.choice(all_eq, 1, replace=False)\n",
    "    [eq2, eq3] = np.random.choice(all_inv, 2, replace=False)\n",
    "    ee_out = (eq1.softmax(-1) + eq2.softmax(-1) + eq3.softmax(-1))/3\n",
    "    nll, ece, acc, _ = get_new_metrics([ee_out],[same_tar],[f'EE_comb{i}'], printing=False, input_softmax=True)    \n",
    "    ee_nll.append(nll)\n",
    "    ee_ece.append(ece)  \n",
    "    ee_acc.append(acc)\n",
    "print(\"EII\")\n",
    "print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.std(ee_nll):.4f}\")\n",
    "print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.std(ee_ece):.4f}\")\n",
    "print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.std(ee_acc):.4f}\")\n",
    "\n",
    "ee_nll = []\n",
    "ee_ece = []\n",
    "ee_acc = []\n",
    "for i in range(num_comb):\n",
    "    [eq1] = np.random.choice(all_eq, 1, replace=False)\n",
    "    [eq2] = np.random.choice(all_inv, 1, replace=False)\n",
    "    [eq3] = np.random.choice(all_base, 1, replace=False)\n",
    "    \n",
    "    ee_out = (eq1.softmax(-1) + eq2.softmax(-1) + eq3.softmax(-1))/3\n",
    "    nll, ece, acc, _ = get_new_metrics([ee_out],[same_tar],[f'EE_comb{i}'], printing=False, input_softmax=True)    \n",
    "    ee_nll.append(nll)\n",
    "    ee_ece.append(ece)  \n",
    "    ee_acc.append(acc)\n",
    "print(\"EBI\")\n",
    "print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.std(ee_nll):.4f}\")\n",
    "print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.std(ee_ece):.4f}\")\n",
    "print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.std(ee_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "necessary-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three models ensembles (excluding all R seeds)\n",
      "EEE\n",
      "NLL: 0.8169083595275879\n",
      "ECE: 0.0158611989844963 0.015861209481954575\n",
      "Acc: 0.7866799831390381\n",
      "BBB\n",
      "NLL: 0.830054759979248\n",
      "ECE: 0.016954529612995678 0.016954533755779266\n",
      "Acc: 0.7847999930381775\n",
      "III\n",
      "NLL: 0.8553289771080017\n",
      "ECE: 0.01828231919476761 0.018282335251569748\n",
      "Acc: 0.7801600098609924\n",
      "BIE\n",
      "NLL: 0.8212129473686218\n",
      "ECE: 0.021877830814775068 0.021877823397517204\n",
      "Acc: 0.7878599762916565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8212129473686218, 0.021877823397517204, 0.7878599762916565)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Three models ensembles (excluding all R seeds)\")\n",
    "eee_out = (eq24_out.softmax(-1) + eq69_out.softmax(-1) + eq42_out.softmax(-1))/3\n",
    "bbb_out = (base31_out.softmax(-1) + base69_out.softmax(-1) + base24_out.softmax(-1))/3\n",
    "iii_out = (inv31_out.softmax(-1) + inv69_out.softmax(-1) + inv_out.softmax(-1))/3\n",
    "bie_out = (base31_out.softmax(-1) + inv_out.softmax(-1) + eq42_out.softmax(-1))/3\n",
    "\n",
    "outs = [eee_out, bbb_out, iii_out, bie_out]\n",
    "names = ['EEE', 'BBB', 'III','BIE']\n",
    "tars = [same_tar, same_tar, same_tar, same_tar]\n",
    "get_metrics_softmax(outs,tars,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "possible-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEE_comb0\n",
      "NLL: 0.8179500102996826\n",
      "ECE: 0.017891318057477436 0.017891312018036842\n",
      "Acc: 0.7876999974250793\n",
      "EEE_comb1\n",
      "NLL: 0.8179499506950378\n",
      "ECE: 0.01789131802232935 0.017891310155391693\n",
      "Acc: 0.7876999974250793\n",
      "EEE_comb2\n",
      "NLL: 0.8169081807136536\n",
      "ECE: 0.015861198693104095 0.015861209481954575\n",
      "Acc: 0.7866799831390381\n",
      "BEI_comb0\n",
      "NLL: 0.8216220140457153\n",
      "ECE: 0.019913184124548008 0.019913190975785255\n",
      "Acc: 0.7864800095558167\n",
      "BEI_comb1\n",
      "NLL: 0.8218128085136414\n",
      "ECE: 0.019601914916858098 0.019601896405220032\n",
      "Acc: 0.7866199612617493\n",
      "BEI_comb2\n",
      "NLL: 0.8229109644889832\n",
      "ECE: 0.02157415859740229 0.02157415822148323\n",
      "Acc: 0.7876399755477905\n",
      "\n",
      "EEE Acc: 0.7873599926630656 +/- 0.0004808393457112864\n",
      "EEE ECE: 0.01721461055179437 +/- 0.0009569990741491496\n",
      "EEE NLL: 0.8176027139027914 +/- 0.0004911091284012794\n",
      "\n",
      "BEI Acc: 0.7869133154551188 +/- 0.0005169930932547092\n",
      "BEI ECE: 0.020363081867496174 +/- 0.0008657388092667003\n",
      "BEI NLL: 0.8221152623494467 +/- 0.0005680123551444188\n"
     ]
    }
   ],
   "source": [
    "num_comb = 3\n",
    "all_eq_exR = [eq24_out, eq69_out, eq42_out, eq31_out]\n",
    "all_base_exR = [base31_out, base24_out, base69_out]\n",
    "all_inv_exR = [inv_out, inv31_out, inv24_out, inv69_out]\n",
    "eee_nll = []\n",
    "eee_ece = []\n",
    "eee_acc = []\n",
    "for i in range(num_comb):\n",
    "    [eq1, eq2, eq3] = np.random.choice(all_eq_exR, 3, replace=False)\n",
    "    eee_out = (eq1.softmax(-1) + eq2.softmax(-1) + eq3.softmax(-1))/3\n",
    "    nll, ece, acc = get_metrics_softmax([eee_out],[same_tar],[f'EEE_comb{i}'])    \n",
    "    eee_nll.append(nll)\n",
    "    eee_ece.append(ece)  \n",
    "    eee_acc.append(acc)   \n",
    "\n",
    "bei_nll = []\n",
    "bei_ece = []\n",
    "bei_acc = []\n",
    "for i in range(num_comb):\n",
    "    [eq1] = np.random.choice(all_eq_exR, 1)\n",
    "    [base1] = np.random.choice(all_base_exR, 1)\n",
    "    [inv1] = np.random.choice(all_inv_exR, 1)\n",
    "    bei_out = (eq1.softmax(-1) + base1.softmax(-1) + inv1.softmax(-1))/3\n",
    "    nll, ece, acc = get_metrics_softmax([bei_out],[same_tar],[f'BEI_comb{i}'])    \n",
    "    bei_nll.append(nll)\n",
    "    bei_ece.append(ece)  \n",
    "    bei_acc.append(acc) \n",
    "\n",
    "print(f\"\\nEEE Acc: {np.mean(eee_acc)} +/- {np.std(eee_acc)}\")\n",
    "print(f\"EEE ECE: {np.mean(eee_ece)} +/- {np.std(eee_ece)}\")\n",
    "print(f\"EEE NLL: {np.mean(eee_nll)} +/- {np.std(eee_nll)}\")\n",
    "\n",
    "print(f\"\\nBEI Acc: {np.mean(bei_acc)} +/- {np.std(bei_acc)}\")\n",
    "print(f\"BEI ECE: {np.mean(bei_ece)} +/- {np.std(bei_ece)}\")\n",
    "print(f\"BEI NLL: {np.mean(bei_nll)} +/- {np.std(bei_nll)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "descending-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Four models ensembles (excluding all R seeds)\n",
      "EEEE\n",
      "NLL: 0.8055247664451599\n",
      "ECE: 0.02062973244084043 0.020629720762372017\n",
      "Acc: 0.7910000085830688\n",
      "BBEE\n",
      "NLL: 0.8093110918998718\n",
      "ECE: 0.020431804699562506 0.020431827753782272\n",
      "Acc: 0.7896199822425842\n",
      "BIEE\n",
      "NLL: 0.8087023496627808\n",
      "ECE: 0.02284597995162008 0.022845963016152382\n",
      "Acc: 0.7899999618530273\n"
     ]
    }
   ],
   "source": [
    "print(\"Four models ensembles (excluding all R seeds)\")\n",
    "eeee_out = (eq69_out.softmax(-1) + eq42_out.softmax(-1) + eq31_out.softmax(-1)+ eq24_out.softmax(-1))/4\n",
    "bbee_out = (base69_out.softmax(-1) + base31_out.softmax(-1) + eq69_out.softmax(-1)+ eq42_out.softmax(-1))/4\n",
    "biee_out = (base69_out.softmax(-1) + inv_out.softmax(-1) + eq69_out.softmax(-1)+ eq42_out.softmax(-1))/4\n",
    "\n",
    "outs = [eeee_out, bbee_out, biee_out]\n",
    "names = ['EEEE', 'BBEE', 'BIEE']\n",
    "tars = [same_tar, same_tar, same_tar]\n",
    "get_metrics_softmax(outs,tars,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "geological-short",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eee_out']\n"
     ]
    }
   ],
   "source": [
    "print(\"5 models ensembles\")\n",
    "eeee_out = (eqR_out.softmax(-1) + eq69_out.softmax(-1) + eq42_out.softmax(-1) + eq31_out.softmax(-1)+ eq24_out.softmax(-1))/5\n",
    "bbiee_out = (baseR_out.softmax(-1) + base31_out.softmax(-1) + inv_out.softmax(-1) + eq69_out.softmax(-1)+ eqR_out.softmax(-1))/5\n",
    "bbbee_out = (baseR_out.softmax(-1) + base31_out.softmax(-1) + base69_out.softmax(-1) + eqR_out.softmax(-1) + eq69_out.softmax(-1))/5\n",
    "bbeee_out = (baseR_out.softmax(-1) + base31_out.softmax(-1) + eqR_out.softmax(-1) + eq69_out.softmax(-1)+ eq42_out.softmax(-1))/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modified-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ft_base_e100_split1_cos_lr0.01_bs256\n",
      "loaded ft_eq_e100_split1_cos_lr0.01_bs256\n",
      "loaded ft_inv_e100_split1_cos_lr0.01_bs256\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_metrics_softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fd27d37ed6f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbei_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase100_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meq100_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minv100_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase100_tar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meq100_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mget_metrics_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbei_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meq100_tar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_metrics_softmax' is not defined"
     ]
    }
   ],
   "source": [
    "base100 = load_1_model(\"ft_base_e100_split1_cos_lr0.01_bs256\")\n",
    "eq100 = load_1_model(\"ft_eq_e100_split1_cos_lr0.01_bs256\")\n",
    "inv100 = load_1_model(\"ft_inv_e100_split1_cos_lr0.01_bs256\")\n",
    "base100_out, base100_tar = rollout_loader(base100, test_loader2)\n",
    "eq100_out, eq100_tar = rollout_loader(eq100, test_loader2)\n",
    "inv100_out, inv100_tar = rollout_loader(inv100, test_loader2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rough-blast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "NLL: 1.1335747241973877\n",
      "ECE: 0.0813031126824394 0.08130313456058502\n",
      "Acc: 0.7318199872970581\n",
      "eq\n",
      "NLL: 1.0972621440887451\n",
      "ECE: 0.0758462802705169 0.07584623992443085\n",
      "Acc: 0.7390599846839905\n",
      "inv\n",
      "NLL: 1.1724555492401123\n",
      "ECE: 0.08375257655128837 0.08375254273414612\n",
      "Acc: 0.7281799912452698\n",
      "bei\n",
      "NLL: 0.9417604804039001\n",
      "ECE: 0.017339948233682657 0.017339937388896942\n",
      "Acc: 0.766539990901947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9417604804039001, 0.017339937388896942, 0.766539990901947)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bei_out = (base100_out.softmax(-1) + eq100_out.softmax(-1) + inv100_out.softmax(-1))/3\n",
    "assert (torch.equal(base100_tar, eq100_tar))\n",
    "assert (torch.equal(base100_tar, inv100_tar))\n",
    "\n",
    "get_metrics_softmax([base100_out.softmax(-1),eq100_out.softmax(-1),inv100_out.softmax(-1),bei_out],[eq100_tar,eq100_tar,eq100_tar,eq100_tar],['base','eq','inv','bei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prepared-homework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./checkpoints/ts_base_ft0.01_split1/checkpoint.pth\n",
      "loaded ./checkpoints/ts_eq_ft0.01_split1/checkpoint.pth\n",
      "loaded ./checkpoints/ts_inv_ft0.01_split1/checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "base100_ts = load_1_ts_model(\"./checkpoints/ts_base_ft0.01_split1/checkpoint.pth\", full_path=True)\n",
    "eq100_ts = load_1_ts_model(\"./checkpoints/ts_eq_ft0.01_split1/checkpoint.pth\", full_path=True)\n",
    "inv100_ts = load_1_ts_model(\"./checkpoints/ts_inv_ft0.01_split1/checkpoint.pth\", full_path=True)\n",
    "\n",
    "base100_ts_out, base100_ts_tar = rollout_loader(base100_ts, test_loader2)\n",
    "eq100_ts_out, eq100_ts_tar = rollout_loader(eq100_ts, test_loader2)\n",
    "inv100_ts_out, inv100_ts_tar = rollout_loader(inv100_ts, test_loader2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cloudy-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_ts\n",
      "NLL: 1.0563137531280518\n",
      "ECE: 0.017097061355728665 0.01709705963730812\n",
      "Acc: 0.7318199872970581\n",
      "eq_ts\n",
      "NLL: 1.0281479358673096\n",
      "ECE: 0.020003060735017078 0.020003043115139008\n",
      "Acc: 0.7390599846839905\n",
      "inv_ts\n",
      "NLL: 1.0874992609024048\n",
      "ECE: 0.021374179718978686 0.021374162286520004\n",
      "Acc: 0.7281799912452698\n",
      "bei_ts\n",
      "NLL: 0.9396365880966187\n",
      "ECE: 0.06822165556107648 0.06822166591882706\n",
      "Acc: 0.7676999568939209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9396365880966187, 0.06822166591882706, 0.7676999568939209)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base100_ts_out_s = (base100_ts_out / base100_ts.temp.item()).softmax(-1)\n",
    "eq100_ts_out_s = (eq100_ts_out / eq100_ts.temp.item()).softmax(-1)\n",
    "inv100_ts_out_s = (inv100_ts_out / inv100_ts.temp.item()).softmax(-1)\n",
    "\n",
    "bei_out_ts = (base100_ts_out_s + eq100_ts_out_s + inv100_ts_out_s)/3\n",
    "\n",
    "get_metrics_softmax([base100_ts_out_s,eq100_ts_out_s,inv100_ts_out_s,bei_out_ts],[base100_ts_tar,base100_ts_tar,base100_ts_tar,base100_ts_tar],['base_ts','eq_ts','inv_ts','bei_ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "solved-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tied fraction: 6e-05\n",
      "conf: tensor([[0.2179, 0.5062, 0.6643,  ..., 0.9480, 0.2598, 0.6143],\n",
      "        [0.6633, 0.8523, 0.7591,  ..., 0.4296, 0.5351, 0.5446],\n",
      "        [0.6853, 0.7718, 0.6159,  ..., 0.7646, 0.4688, 0.4074]],\n",
      "       device='cuda:0')\n",
      "pred: tensor([[  1,   2,   3,  ..., 112, 998, 905],\n",
      "        [396,   3, 394,  ..., 126, 452, 999],\n",
      "        [396,   3, 394,  ..., 998, 419, 700]], device='cuda:0')\n",
      "target: tensor([  1,   2,   3,  ..., 998, 998, 999], device='cuda:0')\n",
      "batch_acc: 0.7615799903869629\n",
      "Acc upper bound: tensor(0.8291, device='cuda:0')\n",
      "tied fraction: 6e-05\n",
      "conf: tensor([[0.1213, 0.4568, 0.5656,  ..., 0.7868, 0.1287, 0.4492],\n",
      "        [0.4211, 0.7652, 0.5960,  ..., 0.2670, 0.3724, 0.3638],\n",
      "        [0.4131, 0.6358, 0.5075,  ..., 0.5446, 0.2754, 0.3012]],\n",
      "       device='cuda:0')\n",
      "pred: tensor([[  1,   2,   3,  ..., 112, 998, 905],\n",
      "        [396,   3, 394,  ..., 126, 452, 999],\n",
      "        [396,   3, 394,  ..., 998, 419, 700]], device='cuda:0')\n",
      "target: tensor([  1,   2,   3,  ..., 998, 998, 999], device='cuda:0')\n",
      "batch_acc: 0.761419951915741\n",
      "Acc upper bound: tensor(0.8291, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "all100 = torch.stack([base100_out,eq100_out,inv100_out])\n",
    "preds, _, _, ub = ensem_pred(all100,mode='hard_vote',target=eq100_tar)\n",
    "all100_ts = torch.stack([(base100_ts_out / base100_ts.temp.item()),(eq100_ts_out / eq100_ts.temp.item()),(inv100_ts_out / inv100_ts.temp.item())])\n",
    "preds_ts, _, _, ub_ts = ensem_pred(all100_ts,mode='hard_vote',target=eq100_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "appointed-tucson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(649, device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "literary-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensem_pred(outputs, mode='DE', num_ensem=3, target=None):\n",
    "    if mode == 'DE':\n",
    "        output = outputs.softmax(dim=-1).mean(dim=0)\n",
    "        _, ensem_preds = output.max(1)\n",
    "        batch_acc = (ensem_preds.long() == target).sum()/ len(target)\n",
    "        # print(\"batch_acc:\", batch_acc.item())\n",
    "        conf, preds = outputs.max(dim=-1) # each has dim (M,B)\n",
    "        pred_exist = (preds == target).sum(dim=0).bool()\n",
    "        acc_ub = 1 - (~pred_exist).sum()/len(pred_exist)\n",
    "\n",
    "        return ensem_preds, target, output, acc_ub * 100, pred_exist\n",
    "\n",
    "    else:\n",
    "        outputs = outputs.softmax(dim=-1)\n",
    "        conf, preds = outputs.max(dim=-1) # each has dim (M,B)\n",
    "        pred_exist = (preds == target).sum(dim=0).bool()\n",
    "        acc_ub = 1 - (~pred_exist).sum()/len(pred_exist)\n",
    "\n",
    "        if mode == 'most_conf':\n",
    "            _, chosen_mem = conf.max(dim=0)\n",
    "            chosen_mem = chosen_mem.unsqueeze(0)\n",
    "            ensem_preds = torch.gather(preds,0,chosen_mem).squeeze(0)\n",
    "            new_target = target\n",
    "        if mode == 'hard_vote':\n",
    "            predmode, count = sp.stats.mode(preds.cpu())\n",
    "            # print(\"all preds:\", preds)\n",
    "            tie = (count < num_ensem - 1)\n",
    "            ensem_preds = torch.Tensor(predmode[~tie]).to(outputs.device) # these are predictions without tie\n",
    "            new_target = target[~tie]\n",
    "            new_conf = conf.T[~tie].T\n",
    "            new_preds = preds.T[~tie].T\n",
    "            if num_ensem != 3:\n",
    "                raise NotImplementedError(\"need to check tie condition\")\n",
    "\n",
    "            if tie.sum() > 0:\n",
    "                tied_conf = conf.T[tie].T\n",
    "                tied_preds = preds.T[tie].T\n",
    "                # For samples under tie, choose the most confident model\n",
    "                _, chosen_mem = tied_conf.max(dim=0)\n",
    "                chosen_mem = chosen_mem.unsqueeze(0)\n",
    "                tpreds = torch.gather(tied_preds,0,chosen_mem).squeeze(0) # these are predictions with tie\n",
    "                ensem_preds = torch.cat([ensem_preds, tpreds],dim=0)\n",
    "                new_target = torch.cat([new_target,target[tie]])\n",
    "                new_conf = torch.cat([new_conf, tied_conf],dim=1)\n",
    "                new_preds = torch.cat([new_preds, tied_preds],dim=1)\n",
    "\n",
    "                print(f\"tied fraction: {len(tied_preds)/len(ensem_preds)}\")\n",
    "            batch_acc = (ensem_preds.long() == new_target).sum()/ len(target)\n",
    "            wrong_samples = (new_target != ensem_preds.long())\n",
    "            wrong_conf = new_conf.T[wrong_samples].T\n",
    "            wrong_preds = new_preds.T[wrong_samples].T\n",
    "            wrong_target = new_target[wrong_samples]\n",
    "            # print(\"target:\", wrong_target)\n",
    "            # print(\"pred matrix:\", wrong_preds)\n",
    "            pred_exist = (wrong_preds == wrong_target).sum(dim=0).bool()\n",
    "            if len(pred_exist) > 0:\n",
    "                print(\"conf:\", wrong_conf.T[pred_exist].T)\n",
    "                print(\"pred:\", wrong_preds.T[pred_exist].T)\n",
    "                print(\"target:\", wrong_target[pred_exist])\n",
    "\n",
    "\n",
    "            # print(\"conf matrix:\", wrong_conf)\n",
    "\n",
    "            print(\"batch_acc:\", batch_acc.item())\n",
    "            print(\"Acc upper bound:\", acc_ub)\n",
    "\n",
    "            assert(ensem_preds.shape[0] == outputs.shape[1])\n",
    "\n",
    "        elif 'soft_vote' in mode: # each member's vote is weighted by its confidence\n",
    "            print(\"Mode:\",mode)\n",
    "            if num_ensem != 3:\n",
    "                raise NotImplementedError(\"need to check tie condition\")\n",
    "            # Can think of a faster way for this later\n",
    "            # weighting only matters to switch decision when predictions are not tied (if 1 member conf > sum of 2 members)\n",
    "            predmode, count = sp.stats.mode(preds.cpu())\n",
    "            tie3 = (count == num_ensem) # if all members agree, prediction is straightforward\n",
    "            ensem_preds = torch.Tensor(predmode[tie3]).to(outputs.device) # these are predictions without tie\n",
    "            new_target = target[tie3]\n",
    "            tie2 = (count == num_ensem - 1)\n",
    "            if tie2.sum() > 0:\n",
    "                newpred = preds.T[tie2].T\n",
    "                newconf =conf.T[tie2].T\n",
    "                pmode = torch.Tensor(predmode[tie2]).long().unsqueeze(0).to(outputs.device)\n",
    "                conf_minority = (newconf * (newpred != pmode)).sum(dim=0)\n",
    "                if mode == 'soft_vote_max':\n",
    "                    conf_majority, _ = (newconf * (newpred == pmode)).max(dim=0)\n",
    "                elif mode == 'soft_vote_sum':\n",
    "                    conf_majority = (newconf * (newpred == pmode)).sum(dim=0)\n",
    "                else:\n",
    "                    raise \"specify soft_vote_max or soft_vote_sum\"\n",
    "                ind_to_switch = conf_minority > conf_majority\n",
    "                ensem_pred1 = newpred[(newpred != pmode)][ind_to_switch]\n",
    "                ensem_pred2 = pmode.squeeze(0)[~ind_to_switch]\n",
    "                ensem_preds = torch.cat([ensem_preds, ensem_pred1, ensem_pred2])\n",
    "                new_target = torch.cat([new_target, target[tie2][ind_to_switch], target[tie2][~ind_to_switch]])\n",
    "                print(f\"switch fraction {len(ensem_pred1)/ (len(ensem_pred1)+len(ensem_pred2))}\")\n",
    "\n",
    "            tie = (count == 1)\n",
    "\n",
    "            if tie.sum() > 0:\n",
    "                tied_conf = conf.T[tie].T\n",
    "                tied_preds = preds.T[tie].T\n",
    "                # For samples under tie, choose the most confident model\n",
    "                _, chosen_mem = tied_conf.max(dim=0)\n",
    "                chosen_mem = chosen_mem.unsqueeze(0)\n",
    "                tied_preds = torch.gather(tied_preds,0,chosen_mem).squeeze(0) # these are predictions with tie\n",
    "                ensem_preds = torch.cat([ensem_preds, tied_preds],dim=0)\n",
    "                new_target = torch.cat([new_target, target[tie]])\n",
    "                print(f\"tied fraction: {len(tied_preds)/len(ensem_preds)}\")\n",
    "            assert(ensem_preds.shape[0] == outputs.shape[1])\n",
    "        return ensem_preds.long(), new_target, None, acc_ub * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sized-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load(\"./checkpoints/ts_base_ft0.01_split1/checkpoint.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "annoying-breakfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['temp', 'members.0.conv1.weight', 'members.0.bn1.weight', 'members.0.bn1.bias', 'members.0.bn1.running_mean', 'members.0.bn1.running_var', 'members.0.bn1.num_batches_tracked', 'members.0.layer1.0.conv1.weight', 'members.0.layer1.0.bn1.weight', 'members.0.layer1.0.bn1.bias', 'members.0.layer1.0.bn1.running_mean', 'members.0.layer1.0.bn1.running_var', 'members.0.layer1.0.bn1.num_batches_tracked', 'members.0.layer1.0.conv2.weight', 'members.0.layer1.0.bn2.weight', 'members.0.layer1.0.bn2.bias', 'members.0.layer1.0.bn2.running_mean', 'members.0.layer1.0.bn2.running_var', 'members.0.layer1.0.bn2.num_batches_tracked', 'members.0.layer1.0.conv3.weight', 'members.0.layer1.0.bn3.weight', 'members.0.layer1.0.bn3.bias', 'members.0.layer1.0.bn3.running_mean', 'members.0.layer1.0.bn3.running_var', 'members.0.layer1.0.bn3.num_batches_tracked', 'members.0.layer1.0.downsample.0.weight', 'members.0.layer1.0.downsample.1.weight', 'members.0.layer1.0.downsample.1.bias', 'members.0.layer1.0.downsample.1.running_mean', 'members.0.layer1.0.downsample.1.running_var', 'members.0.layer1.0.downsample.1.num_batches_tracked', 'members.0.layer1.1.conv1.weight', 'members.0.layer1.1.bn1.weight', 'members.0.layer1.1.bn1.bias', 'members.0.layer1.1.bn1.running_mean', 'members.0.layer1.1.bn1.running_var', 'members.0.layer1.1.bn1.num_batches_tracked', 'members.0.layer1.1.conv2.weight', 'members.0.layer1.1.bn2.weight', 'members.0.layer1.1.bn2.bias', 'members.0.layer1.1.bn2.running_mean', 'members.0.layer1.1.bn2.running_var', 'members.0.layer1.1.bn2.num_batches_tracked', 'members.0.layer1.1.conv3.weight', 'members.0.layer1.1.bn3.weight', 'members.0.layer1.1.bn3.bias', 'members.0.layer1.1.bn3.running_mean', 'members.0.layer1.1.bn3.running_var', 'members.0.layer1.1.bn3.num_batches_tracked', 'members.0.layer1.2.conv1.weight', 'members.0.layer1.2.bn1.weight', 'members.0.layer1.2.bn1.bias', 'members.0.layer1.2.bn1.running_mean', 'members.0.layer1.2.bn1.running_var', 'members.0.layer1.2.bn1.num_batches_tracked', 'members.0.layer1.2.conv2.weight', 'members.0.layer1.2.bn2.weight', 'members.0.layer1.2.bn2.bias', 'members.0.layer1.2.bn2.running_mean', 'members.0.layer1.2.bn2.running_var', 'members.0.layer1.2.bn2.num_batches_tracked', 'members.0.layer1.2.conv3.weight', 'members.0.layer1.2.bn3.weight', 'members.0.layer1.2.bn3.bias', 'members.0.layer1.2.bn3.running_mean', 'members.0.layer1.2.bn3.running_var', 'members.0.layer1.2.bn3.num_batches_tracked', 'members.0.layer2.0.conv1.weight', 'members.0.layer2.0.bn1.weight', 'members.0.layer2.0.bn1.bias', 'members.0.layer2.0.bn1.running_mean', 'members.0.layer2.0.bn1.running_var', 'members.0.layer2.0.bn1.num_batches_tracked', 'members.0.layer2.0.conv2.weight', 'members.0.layer2.0.bn2.weight', 'members.0.layer2.0.bn2.bias', 'members.0.layer2.0.bn2.running_mean', 'members.0.layer2.0.bn2.running_var', 'members.0.layer2.0.bn2.num_batches_tracked', 'members.0.layer2.0.conv3.weight', 'members.0.layer2.0.bn3.weight', 'members.0.layer2.0.bn3.bias', 'members.0.layer2.0.bn3.running_mean', 'members.0.layer2.0.bn3.running_var', 'members.0.layer2.0.bn3.num_batches_tracked', 'members.0.layer2.0.downsample.0.weight', 'members.0.layer2.0.downsample.1.weight', 'members.0.layer2.0.downsample.1.bias', 'members.0.layer2.0.downsample.1.running_mean', 'members.0.layer2.0.downsample.1.running_var', 'members.0.layer2.0.downsample.1.num_batches_tracked', 'members.0.layer2.1.conv1.weight', 'members.0.layer2.1.bn1.weight', 'members.0.layer2.1.bn1.bias', 'members.0.layer2.1.bn1.running_mean', 'members.0.layer2.1.bn1.running_var', 'members.0.layer2.1.bn1.num_batches_tracked', 'members.0.layer2.1.conv2.weight', 'members.0.layer2.1.bn2.weight', 'members.0.layer2.1.bn2.bias', 'members.0.layer2.1.bn2.running_mean', 'members.0.layer2.1.bn2.running_var', 'members.0.layer2.1.bn2.num_batches_tracked', 'members.0.layer2.1.conv3.weight', 'members.0.layer2.1.bn3.weight', 'members.0.layer2.1.bn3.bias', 'members.0.layer2.1.bn3.running_mean', 'members.0.layer2.1.bn3.running_var', 'members.0.layer2.1.bn3.num_batches_tracked', 'members.0.layer2.2.conv1.weight', 'members.0.layer2.2.bn1.weight', 'members.0.layer2.2.bn1.bias', 'members.0.layer2.2.bn1.running_mean', 'members.0.layer2.2.bn1.running_var', 'members.0.layer2.2.bn1.num_batches_tracked', 'members.0.layer2.2.conv2.weight', 'members.0.layer2.2.bn2.weight', 'members.0.layer2.2.bn2.bias', 'members.0.layer2.2.bn2.running_mean', 'members.0.layer2.2.bn2.running_var', 'members.0.layer2.2.bn2.num_batches_tracked', 'members.0.layer2.2.conv3.weight', 'members.0.layer2.2.bn3.weight', 'members.0.layer2.2.bn3.bias', 'members.0.layer2.2.bn3.running_mean', 'members.0.layer2.2.bn3.running_var', 'members.0.layer2.2.bn3.num_batches_tracked', 'members.0.layer2.3.conv1.weight', 'members.0.layer2.3.bn1.weight', 'members.0.layer2.3.bn1.bias', 'members.0.layer2.3.bn1.running_mean', 'members.0.layer2.3.bn1.running_var', 'members.0.layer2.3.bn1.num_batches_tracked', 'members.0.layer2.3.conv2.weight', 'members.0.layer2.3.bn2.weight', 'members.0.layer2.3.bn2.bias', 'members.0.layer2.3.bn2.running_mean', 'members.0.layer2.3.bn2.running_var', 'members.0.layer2.3.bn2.num_batches_tracked', 'members.0.layer2.3.conv3.weight', 'members.0.layer2.3.bn3.weight', 'members.0.layer2.3.bn3.bias', 'members.0.layer2.3.bn3.running_mean', 'members.0.layer2.3.bn3.running_var', 'members.0.layer2.3.bn3.num_batches_tracked', 'members.0.layer3.0.conv1.weight', 'members.0.layer3.0.bn1.weight', 'members.0.layer3.0.bn1.bias', 'members.0.layer3.0.bn1.running_mean', 'members.0.layer3.0.bn1.running_var', 'members.0.layer3.0.bn1.num_batches_tracked', 'members.0.layer3.0.conv2.weight', 'members.0.layer3.0.bn2.weight', 'members.0.layer3.0.bn2.bias', 'members.0.layer3.0.bn2.running_mean', 'members.0.layer3.0.bn2.running_var', 'members.0.layer3.0.bn2.num_batches_tracked', 'members.0.layer3.0.conv3.weight', 'members.0.layer3.0.bn3.weight', 'members.0.layer3.0.bn3.bias', 'members.0.layer3.0.bn3.running_mean', 'members.0.layer3.0.bn3.running_var', 'members.0.layer3.0.bn3.num_batches_tracked', 'members.0.layer3.0.downsample.0.weight', 'members.0.layer3.0.downsample.1.weight', 'members.0.layer3.0.downsample.1.bias', 'members.0.layer3.0.downsample.1.running_mean', 'members.0.layer3.0.downsample.1.running_var', 'members.0.layer3.0.downsample.1.num_batches_tracked', 'members.0.layer3.1.conv1.weight', 'members.0.layer3.1.bn1.weight', 'members.0.layer3.1.bn1.bias', 'members.0.layer3.1.bn1.running_mean', 'members.0.layer3.1.bn1.running_var', 'members.0.layer3.1.bn1.num_batches_tracked', 'members.0.layer3.1.conv2.weight', 'members.0.layer3.1.bn2.weight', 'members.0.layer3.1.bn2.bias', 'members.0.layer3.1.bn2.running_mean', 'members.0.layer3.1.bn2.running_var', 'members.0.layer3.1.bn2.num_batches_tracked', 'members.0.layer3.1.conv3.weight', 'members.0.layer3.1.bn3.weight', 'members.0.layer3.1.bn3.bias', 'members.0.layer3.1.bn3.running_mean', 'members.0.layer3.1.bn3.running_var', 'members.0.layer3.1.bn3.num_batches_tracked', 'members.0.layer3.2.conv1.weight', 'members.0.layer3.2.bn1.weight', 'members.0.layer3.2.bn1.bias', 'members.0.layer3.2.bn1.running_mean', 'members.0.layer3.2.bn1.running_var', 'members.0.layer3.2.bn1.num_batches_tracked', 'members.0.layer3.2.conv2.weight', 'members.0.layer3.2.bn2.weight', 'members.0.layer3.2.bn2.bias', 'members.0.layer3.2.bn2.running_mean', 'members.0.layer3.2.bn2.running_var', 'members.0.layer3.2.bn2.num_batches_tracked', 'members.0.layer3.2.conv3.weight', 'members.0.layer3.2.bn3.weight', 'members.0.layer3.2.bn3.bias', 'members.0.layer3.2.bn3.running_mean', 'members.0.layer3.2.bn3.running_var', 'members.0.layer3.2.bn3.num_batches_tracked', 'members.0.layer3.3.conv1.weight', 'members.0.layer3.3.bn1.weight', 'members.0.layer3.3.bn1.bias', 'members.0.layer3.3.bn1.running_mean', 'members.0.layer3.3.bn1.running_var', 'members.0.layer3.3.bn1.num_batches_tracked', 'members.0.layer3.3.conv2.weight', 'members.0.layer3.3.bn2.weight', 'members.0.layer3.3.bn2.bias', 'members.0.layer3.3.bn2.running_mean', 'members.0.layer3.3.bn2.running_var', 'members.0.layer3.3.bn2.num_batches_tracked', 'members.0.layer3.3.conv3.weight', 'members.0.layer3.3.bn3.weight', 'members.0.layer3.3.bn3.bias', 'members.0.layer3.3.bn3.running_mean', 'members.0.layer3.3.bn3.running_var', 'members.0.layer3.3.bn3.num_batches_tracked', 'members.0.layer3.4.conv1.weight', 'members.0.layer3.4.bn1.weight', 'members.0.layer3.4.bn1.bias', 'members.0.layer3.4.bn1.running_mean', 'members.0.layer3.4.bn1.running_var', 'members.0.layer3.4.bn1.num_batches_tracked', 'members.0.layer3.4.conv2.weight', 'members.0.layer3.4.bn2.weight', 'members.0.layer3.4.bn2.bias', 'members.0.layer3.4.bn2.running_mean', 'members.0.layer3.4.bn2.running_var', 'members.0.layer3.4.bn2.num_batches_tracked', 'members.0.layer3.4.conv3.weight', 'members.0.layer3.4.bn3.weight', 'members.0.layer3.4.bn3.bias', 'members.0.layer3.4.bn3.running_mean', 'members.0.layer3.4.bn3.running_var', 'members.0.layer3.4.bn3.num_batches_tracked', 'members.0.layer3.5.conv1.weight', 'members.0.layer3.5.bn1.weight', 'members.0.layer3.5.bn1.bias', 'members.0.layer3.5.bn1.running_mean', 'members.0.layer3.5.bn1.running_var', 'members.0.layer3.5.bn1.num_batches_tracked', 'members.0.layer3.5.conv2.weight', 'members.0.layer3.5.bn2.weight', 'members.0.layer3.5.bn2.bias', 'members.0.layer3.5.bn2.running_mean', 'members.0.layer3.5.bn2.running_var', 'members.0.layer3.5.bn2.num_batches_tracked', 'members.0.layer3.5.conv3.weight', 'members.0.layer3.5.bn3.weight', 'members.0.layer3.5.bn3.bias', 'members.0.layer3.5.bn3.running_mean', 'members.0.layer3.5.bn3.running_var', 'members.0.layer3.5.bn3.num_batches_tracked', 'members.0.layer4.0.conv1.weight', 'members.0.layer4.0.bn1.weight', 'members.0.layer4.0.bn1.bias', 'members.0.layer4.0.bn1.running_mean', 'members.0.layer4.0.bn1.running_var', 'members.0.layer4.0.bn1.num_batches_tracked', 'members.0.layer4.0.conv2.weight', 'members.0.layer4.0.bn2.weight', 'members.0.layer4.0.bn2.bias', 'members.0.layer4.0.bn2.running_mean', 'members.0.layer4.0.bn2.running_var', 'members.0.layer4.0.bn2.num_batches_tracked', 'members.0.layer4.0.conv3.weight', 'members.0.layer4.0.bn3.weight', 'members.0.layer4.0.bn3.bias', 'members.0.layer4.0.bn3.running_mean', 'members.0.layer4.0.bn3.running_var', 'members.0.layer4.0.bn3.num_batches_tracked', 'members.0.layer4.0.downsample.0.weight', 'members.0.layer4.0.downsample.1.weight', 'members.0.layer4.0.downsample.1.bias', 'members.0.layer4.0.downsample.1.running_mean', 'members.0.layer4.0.downsample.1.running_var', 'members.0.layer4.0.downsample.1.num_batches_tracked', 'members.0.layer4.1.conv1.weight', 'members.0.layer4.1.bn1.weight', 'members.0.layer4.1.bn1.bias', 'members.0.layer4.1.bn1.running_mean', 'members.0.layer4.1.bn1.running_var', 'members.0.layer4.1.bn1.num_batches_tracked', 'members.0.layer4.1.conv2.weight', 'members.0.layer4.1.bn2.weight', 'members.0.layer4.1.bn2.bias', 'members.0.layer4.1.bn2.running_mean', 'members.0.layer4.1.bn2.running_var', 'members.0.layer4.1.bn2.num_batches_tracked', 'members.0.layer4.1.conv3.weight', 'members.0.layer4.1.bn3.weight', 'members.0.layer4.1.bn3.bias', 'members.0.layer4.1.bn3.running_mean', 'members.0.layer4.1.bn3.running_var', 'members.0.layer4.1.bn3.num_batches_tracked', 'members.0.layer4.2.conv1.weight', 'members.0.layer4.2.bn1.weight', 'members.0.layer4.2.bn1.bias', 'members.0.layer4.2.bn1.running_mean', 'members.0.layer4.2.bn1.running_var', 'members.0.layer4.2.bn1.num_batches_tracked', 'members.0.layer4.2.conv2.weight', 'members.0.layer4.2.bn2.weight', 'members.0.layer4.2.bn2.bias', 'members.0.layer4.2.bn2.running_mean', 'members.0.layer4.2.bn2.running_var', 'members.0.layer4.2.bn2.num_batches_tracked', 'members.0.layer4.2.conv3.weight', 'members.0.layer4.2.bn3.weight', 'members.0.layer4.2.bn3.bias', 'members.0.layer4.2.bn3.running_mean', 'members.0.layer4.2.bn3.running_var', 'members.0.layer4.2.bn3.num_batches_tracked', 'members.0.fc.weight', 'members.0.fc.bias'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "finite-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "y_true = all_targets.cpu().numpy()\n",
    "probs = all_outputs.softmax(-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "treated-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(labels, softmaxes, name=None):\n",
    "    '''The [Brier score][1] is a loss function for probabilistic predictions over a\n",
    "  number of discrete outcomes.  For a probability vector `p` and a realized\n",
    "  outcome `k` the Brier score is `sum_i p[i]*p[i] - 2*p[k]`. '''\n",
    "#     labels = tf.convert_to_tensor(labels)\n",
    "#     logits = tf.convert_to_tensor(logits)\n",
    "#     probabilities = tf.math.softmax(logits, axis=1)\n",
    "\n",
    "    num_classes = softmaxes.shape[-1]\n",
    "    plabel = softmaxes * torch.nn.functional.one_hot(labels, num_classes)\n",
    "    plabel = plabel.sum(-1)\n",
    "    brier = (softmaxes ** 2).sum(-1) - 2. * plabel\n",
    "    return brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sporting-housing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6700, device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(brier_score(all_targets,all_outputs.softmax(-1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "partial-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([probs[i, idx] for i, idx in enumerate(y_true)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unauthorized-sewing",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only binary classification is supported. The type of the target is multiclass.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-99144b5c63cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_prob_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Probability of positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbrier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrier_score_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_prob_true\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Brier Score (MSE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/barn/miniconda3/envs/py37/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mbrier_score_loss\u001b[0;34m(y_true, y_prob, sample_weight, pos_label)\u001b[0m\n\u001b[1;32m   2668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         raise ValueError(\n\u001b[0;32m-> 2670\u001b[0;31m             \u001b[0;34m\"Only binary classification is supported. The type of the target \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2671\u001b[0m             \u001b[0;34mf\"is {y_type}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Only binary classification is supported. The type of the target is multiclass."
     ]
    }
   ],
   "source": [
    "y_prob_true = np.array([probs[i, idx] for i, idx in enumerate(y_true)])  # Probability of positive class\n",
    "brier = brier_score_loss(y_true=y_true, y_prob=y_prob_true)  # Brier Score (MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_ensem, ece1, ece2, ece3 = 0., 0., 0., 0.\n",
    "nll_ensem, nll1, nll2, nll3 = 0., 0., 0., 0.\n",
    "\n",
    "\n",
    "targets = []\n",
    "for it, (img, target) in enumerate(test_loader2):\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    img = img.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        output1 = model1(img)\n",
    "        output2 = model2(img)\n",
    "        output3 = model3(img)\n",
    "        preds = torch.stack([output1,output2,output3])      \n",
    "        naive_ensem = preds.softmax(dim=-1).mean(dim=0)\n",
    "        ece_1 = ece_criterion(output1.softmax(-1), target)\n",
    "        ece_2 = ece_criterion(output2.softmax(-1), target)\n",
    "        ece_3 = ece_criterion(output3.softmax(-1), target)\n",
    "        ece_e = ece_criterion(naive_ensem, target)  \n",
    "        ece1 += ece_1\n",
    "        ece2 += ece_2 \n",
    "        ece3 += ece_3      \n",
    "        ece_ensem += ece_e\n",
    "#         print(ece_1, ece_2, ece_3)\n",
    "#         nll1 += nll_criterion(output1.softmax(-1), target) \n",
    "#         nll2 += nll_criterion(output2.softmax(-1), target)  \n",
    "#         nll3 += nll_criterion(output3.softmax(-1), target)      \n",
    "#         nll_ensem += nll_criterion(naive_ensem, target) \n",
    "\n",
    "print(ece1/len(test_loader2), ece2/len(test_loader2),ece3/len(test_loader2))\n",
    "print(ece_ensem/len(test_loader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-image",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
