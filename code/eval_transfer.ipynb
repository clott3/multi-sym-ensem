{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "female-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from datasets import Split_Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder, CIFAR10, CIFAR100\n",
    "from datasets_v08 import Flowers102\n",
    "\n",
    "c100_norm = transforms.Normalize([0.50707516,  0.48654887,  0.44091784], [0.26733429,  0.25643846,  0.27615047])\n",
    "flowers_norm = transforms.Normalize([0.5153, 0.4172, 0.3444], [0.2981, 0.2516, 0.2915])\n",
    "\n",
    "num_classes = 100\n",
    "\n",
    "c100_val_transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            c100_norm\n",
    "        ])\n",
    "\n",
    "flowers_val_transforms = transforms.Compose([\n",
    "        transforms.Resize(224+32),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        flowers_norm\n",
    "    ])\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "test_dataset = datasets.ImageFolder('/gpfs/u/locker/200/CADS/datasets/ImageNet/val', transform=val_transforms)\n",
    "\n",
    "val_dataset = Split_Dataset('/gpfs/u/locker/200/CADS/datasets/ImageNet',  \\\n",
    "                    f'./calib_splits/am_imagenet_5percent_val.txt',\n",
    "                    transform=val_transforms)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "c100_dataset = CIFAR100(\"/gpfs/u/home/BNSS/BNSSlhch/scratch/datasets/\", train=False, transform=c100_val_transforms,download=False)\n",
    "flowers_dataset = Flowers102(\"/gpfs/u/home/BNSS/BNSSlhch/scratch/datasets/\", split='test', transform=flowers_val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "realistic-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "c100_loader = torch.utils.data.DataLoader(\n",
    "            c100_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )\n",
    "flowers_loader = torch.utils.data.DataLoader(\n",
    "            flowers_dataset, batch_size=256, shuffle=False,\n",
    "            num_workers=20, pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oriented-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_1_model(ckpt_path, full_path=False, num_classes=1000):\n",
    "    model1 = models.resnet50(num_classes=num_classes).cuda()\n",
    "    if not full_path:\n",
    "        sd = torch.load(f\"./dist_models/{ckpt_path}/checkpoint_best.pth\", map_location=\"cpu\")\n",
    "    else:\n",
    "        sd = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    ckpt = {k.replace(\"members.0.\",\"\"):v for k,v in sd['model'].items()}\n",
    "    model1.load_state_dict(ckpt)\n",
    "    print(f\"loaded {ckpt_path}\")\n",
    "    model1.eval()\n",
    "    return model1\n",
    "\n",
    "def rollout_loader(model, loader):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for it, (img, target) in enumerate(loader):\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        img = img.cuda(non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            output1 = model(img)\n",
    "#             ece_1 = ece_criterion(output1.softmax(-1), target)\n",
    "            targets.append(target)\n",
    "            outputs.append(output1)\n",
    "    return torch.cat(outputs), torch.cat(targets)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import inspect\n",
    "from netcal.metrics import ECE\n",
    "\n",
    "cecriterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "nll_criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "# ece_criterion = _ECELoss().cuda()\n",
    "ece_netcal = ECE(15)\n",
    "\n",
    "def get_metrics(outs, tars, names, printing=True, input_softmax=False, num_classes=1000):\n",
    "\n",
    "    for out, tar,name in zip(outs,tars,names):\n",
    "        correct_per_class = torch.zeros(num_classes).to(tar.device)\n",
    "        total_per_class = torch.zeros(num_classes).to(tar.device)\n",
    "\n",
    "        if not input_softmax:\n",
    "            out = out.softmax(-1)\n",
    "        ece1 = ece_netcal.measure(out.cpu().numpy(), tar.cpu().numpy())\n",
    "#         ece2 = ece_criterion(out, tar)\n",
    "        loss = F.nll_loss(torch.log(out), tar)\n",
    "        _, pred = out.max(-1)\n",
    "        correct_vec = (pred == tar)\n",
    "        ind_per_class = (tar.unsqueeze(1) == torch.arange(num_classes).to(tar.device)) # indicator variable for each class\n",
    "        correct_per_class = (correct_vec.unsqueeze(1) * ind_per_class).sum(0)\n",
    "        total_per_class = ind_per_class.sum(0)\n",
    "\n",
    "        acc = (correct_vec.sum()) / len(tar)\n",
    "        acc_per_class = correct_per_class / total_per_class\n",
    "        if printing:\n",
    "            print(name)\n",
    "            print(f\"NLL: {loss.item()} | ECE: {ece1}\")\n",
    "            print(\"Acc:\", acc.item())\n",
    "    return loss.item(), ece1, acc.item(), acc_per_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sized-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLD(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLD, self).__init__()\n",
    "        self.kl = torch.nn.KLDivLoss(reduction='sum', log_target=True)\n",
    "\n",
    "    def forward(self, p: torch.tensor, q: torch.tensor):\n",
    "        p = F.log_softmax(p, dim=-1)\n",
    "        q = F.log_softmax(q, dim=-1)\n",
    "        return self.kl(p,q)\n",
    "\n",
    "kl_div = KLD()\n",
    "\n",
    "def compute_pair_consensus(pair_preds, target):\n",
    "    agree = (pair_preds[0] == pair_preds[1])\n",
    "    agree_correct = agree & (pair_preds[0] == target)\n",
    "    agree_wrong = agree & (pair_preds[0] != target)\n",
    "    disagree = (pair_preds[0] != pair_preds[1])\n",
    "    disagree_both_wrong = disagree & (pair_preds[0] != target) & (pair_preds[1] != target)\n",
    "    disagree_one_correct = disagree & (pair_preds[0] != target) & (pair_preds[1] == target) \n",
    "    disagree_one_correct2 = disagree & (pair_preds[1] != target) & (pair_preds[0] == target) \n",
    "    return agree.sum(), disagree.sum(), agree_correct.sum(), agree_wrong.sum(), disagree_both_wrong.sum(), disagree_one_correct.sum()+disagree_one_correct2.sum()\n",
    "\n",
    "def get_div_metrics(output1,output2,output3,target):\n",
    "    preds = torch.stack([output1,output2,output3])\n",
    "    avg_std_logits = torch.std(preds, dim=0).mean(dim=-1).mean() # std over members, mean over classes, sum over samples (mean taken later))\n",
    "    avg_std = torch.std(preds.softmax(-1), dim=0).mean(dim=-1).mean() # std over members, mean over classes, sum over samples (mean taken later))\n",
    "    _, all_preds = preds.max(-1)\n",
    "    ag_p, dag_p, ag_c_p, ag_w_p, dag_w_p, dag_c_p = 0, 0, 0, 0, 0, 0\n",
    "    kld = 0.\n",
    "    pairs = ([0,1], [0,2], [1,2])\n",
    "    for p in pairs:\n",
    "        ag, dag, ag_c, ag_w, dag_w, dag_c = compute_pair_consensus(all_preds[p,:], target)\n",
    "        ag_p += ag\n",
    "        dag_p += dag\n",
    "        ag_c_p += ag_c\n",
    "        ag_w_p += ag_w\n",
    "        dag_c_p += dag_c\n",
    "        dag_w_p += dag_w\n",
    "        kld += kl_div(preds[p[0]], preds[p[1]])\n",
    "\n",
    "    ag_sum = ag_p/len(pairs)\n",
    "    dag_sum = dag_p/len(pairs)\n",
    "    ag_c_sum = ag_c_p/len(pairs)\n",
    "    ag_w_sum = ag_w_p/len(pairs)\n",
    "    dag_c_sum = dag_c_p/len(pairs)\n",
    "    dag_w_sum = dag_w_p/len(pairs)\n",
    "    kld_sum = kld/len(pairs)\n",
    "    print(f\"Diversity agree: {ag_sum/len(output1)} | disagree: {dag_sum/len(output1)}\") \n",
    "#     print(f\"Ensemble Variance Logits: {avg_std_logits} \") \n",
    "#     print(f\"Ensemble Variance: {avg_std}\") \n",
    "#     print(f\"KL div: {kld_sum/len(output1)}\") \n",
    "    return ag_sum/len(output1), dag_sum/len(output1), kld_sum/len(output1), avg_std_logits, avg_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convertible-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get classwise stats\n",
    "def get_classwise(acc_base, acc_rotinv, acc_roteq, num_classes=1000):\n",
    "    print(\"use order B, I, E\")\n",
    "    y = torch.stack([v for v in [acc_base, acc_rotinv, acc_roteq]], dim=-1)\n",
    "\n",
    "    fac = num_classes/100\n",
    "    # all 3 models equally good\n",
    "    best_base_inv_eq = (y[:,0] == y[:,1]) & (y[:,1] == y[:,2])\n",
    "    # 2 models equally good and is better\n",
    "    best_base_inv = (y[:,0] == y[:,1]) & (y[:,0] > y[:,2])\n",
    "    best_base_eq = (y[:,0] == y[:,2]) & (y[:,0] > y[:,1])\n",
    "    best_inv_eq = (y[:,1] == y[:,2]) & (y[:,1] > y[:,0])\n",
    "    # 2 models equally good and is worse\n",
    "    worse_base_inv = (y[:,0] == y[:,1]) & (y[:,0] < y[:,2]) # best eq\n",
    "    worse_base_eq = (y[:,0] == y[:,2]) & (y[:,0] < y[:,1]) # best inv\n",
    "    worse_inv_eq = (y[:,1] == y[:,2]) & (y[:,1] < y[:,0]) # best base\n",
    "    all_diff = (y[:,0] != y[:,1]) & (y[:,1] != y[:,2]) & (y[:,0] != y[:,2])\n",
    "    print(f\"all equal best: {(best_base_inv_eq.sum())/fac:.1f}%\")\n",
    "    print(f\"B,I equal best: {(best_base_inv.sum())/fac:.1f}%\")\n",
    "    print(f\"B,E equal best: {(best_base_eq.sum())/fac:.1f}%\")\n",
    "    print(f\"I,E equal best: {(best_inv_eq.sum())/fac:.1f}%\")\n",
    "    # print(f\"all diff: {all_diff.sum()}\")\n",
    "    total = best_base_inv_eq.sum() + best_base_inv.sum() + best_base_eq.sum() + best_inv_eq.sum() + all_diff.sum() + worse_inv_eq.sum() + worse_base_eq.sum() + worse_base_inv.sum()\n",
    "    assert total == num_classes\n",
    "\n",
    "    # for all diff \n",
    "    best_base = (y[:,0] > y[:,1]) & (y[:,0] > y[:,2]) & all_diff\n",
    "    best_inv = (y[:,1] > y[:,0]) & (y[:,1] > y[:,2]) & all_diff\n",
    "    best_eq = (y[:,2] > y[:,0]) & (y[:,2] > y[:,1]) & all_diff\n",
    "    total_unique = best_base.sum()+best_inv.sum()+best_eq.sum()\n",
    "    assert total_unique == all_diff.sum()\n",
    "\n",
    "    # single model uniquely best\n",
    "    b_uniq = best_base | worse_inv_eq\n",
    "    i_uniq = best_inv | worse_base_eq\n",
    "    e_uniq = best_eq | worse_base_inv\n",
    "    print(f\"B uniquely best: {b_uniq.sum()/fac:.1f}%\")\n",
    "    print(f\"I uniquely best: {(best_inv.sum() + worse_base_eq.sum())/fac:.1f}%\")\n",
    "    print(f\"E uniquely best: {(best_eq.sum() + worse_base_inv.sum())/fac:.1f}%\")\n",
    "\n",
    "    B_good = b_uniq | best_base_inv_eq | best_base_inv | best_base_eq\n",
    "    I_good = i_uniq | best_base_inv_eq | best_base_inv | best_inv_eq\n",
    "    E_good = e_uniq | best_base_inv_eq | best_base_eq | best_inv_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "occupied-throat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded trans_flowers102_base69_cos_lr0.8_bs256\n",
      "loaded trans_flowers102_eq69_cos_lr0.8_bs256\n",
      "loaded trans_flowers102_inv69_cos_lr0.8_bs256\n",
      "loaded trans_flowers102_base24_cos_lr0.5_bs256\n",
      "loaded trans_flowers102_eq24_cos_lr0.8_bs256\n",
      "loaded trans_flowers102_inv24_cos_lr0.5_bs256\n",
      "loaded trans_flowers102_base31_cos_lr0.5_bs256\n",
      "loaded trans_flowers102_eq31_cos_lr0.5_bs256\n",
      "loaded trans_flowers102_inv31_cos_lr0.3_bs256\n"
     ]
    }
   ],
   "source": [
    "# Flowers\n",
    "dataset_name = 'flowers102'\n",
    "num_classes = 102\n",
    "lr = '0.5'\n",
    "loader = flowers_loader\n",
    "\n",
    "b69 = load_1_model(f\"trans_{dataset_name}_base69_cos_lr0.8_bs256\", num_classes=num_classes)\n",
    "b69_out_f, b69_tar = rollout_loader(b69, loader)\n",
    "eq69 = load_1_model(f\"trans_{dataset_name}_eq69_cos_lr0.8_bs256\", num_classes=num_classes)\n",
    "eq69_out_f, eq69_tar = rollout_loader(eq69, loader)\n",
    "inv69 = load_1_model(f\"trans_{dataset_name}_inv69_cos_lr0.8_bs256\", num_classes=num_classes)\n",
    "inv69_out_f, inv69_tar = rollout_loader(inv69, loader)\n",
    "assert(torch.equal(b69_tar,eq69_tar))\n",
    "\n",
    "b24 = load_1_model(f\"trans_{dataset_name}_base24_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "b24_out_f, _ = rollout_loader(b24, loader)\n",
    "eq24 = load_1_model(f\"trans_{dataset_name}_eq24_cos_lr0.8_bs256\", num_classes=num_classes)\n",
    "eq24_out_f, _ = rollout_loader(eq24, loader)\n",
    "inv24 = load_1_model(f\"trans_{dataset_name}_inv24_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "inv24_out_f, _ = rollout_loader(inv24, loader)\n",
    "\n",
    "b31 = load_1_model(f\"trans_{dataset_name}_base31_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "b31_out_f, _ = rollout_loader(b31, loader)\n",
    "eq31 = load_1_model(f\"trans_{dataset_name}_eq31_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "eq31_out_f, _ = rollout_loader(eq24, loader)\n",
    "inv31 = load_1_model(f\"trans_{dataset_name}_inv31_cos_lr0.3_bs256\", num_classes=num_classes)\n",
    "inv31_out_f, _ = rollout_loader(inv31, loader)\n",
    "\n",
    "tar_f = b69_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "original-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded trans_flowers102_eq42_cos_lr0.8_bs256\n"
     ]
    }
   ],
   "source": [
    "eq42 = load_1_model(f\"trans_{dataset_name}_eq42_cos_lr0.8_bs256\", num_classes=num_classes)\n",
    "eq42_out_f, _ = rollout_loader(eq24, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "owned-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metrics import get_metrics as get_new_metrics\n",
    "\n",
    "def ensem_BEI(all_eq,all_base,all_inv,same_tar,num_E=0, num_B=0, num_I=0, num_comb=5, err='std'):\n",
    "    ee_nll = []\n",
    "    ee_ece = []\n",
    "    ee_acc = []\n",
    "    for i in range(num_comb):\n",
    "        eq_list = np.random.choice(all_eq, num_E, replace=False)\n",
    "        base_list = np.random.choice(all_base, num_B, replace=False)\n",
    "        inv_list = np.random.choice(all_inv, num_I, replace=False)\n",
    "        out_list = list(eq_list) + list(base_list) + list(inv_list)\n",
    "        out_list = [torch.Tensor(x.cpu()) for x in out_list]\n",
    "        ee_out = torch.stack(out_list).softmax(-1).mean(dim=0).cuda()\n",
    "        nll, ece, acc, _ = get_new_metrics([ee_out],[same_tar],[f'EE_comb{i}'], printing=False, input_softmax=True)    \n",
    "        ee_nll.append(nll)\n",
    "        ee_ece.append(ece)  \n",
    "        ee_acc.append(acc)\n",
    "    print(\"E\"*num_E + \"B\"*num_B + \"I\"*num_I)\n",
    "    if err=='std':\n",
    "        print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.std(ee_nll):.4f}\")\n",
    "        print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.std(ee_ece):.4f}\")\n",
    "        print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.std(ee_acc):.4f}\")\n",
    "    elif err=='var':\n",
    "        print(f\"NLL: {np.mean(ee_nll):.4f} +/- {np.var(ee_nll):.4f}\")\n",
    "        print(f\"ECE: {np.mean(ee_ece):.4f} +/- {np.var(ee_ece):.4f}\")\n",
    "        print(f\"Acc: {np.mean(ee_acc):.4f} +/- {np.var(ee_acc):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "junior-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "NLL: 0.3570 +/- 0.0112\n",
      "ECE: 0.0269 +/- 0.0020\n",
      "Acc: 0.9191 +/- 0.0003\n",
      "B\n",
      "NLL: 0.3079 +/- 0.0156\n",
      "ECE: 0.0109 +/- 0.0028\n",
      "Acc: 0.9217 +/- 0.0019\n",
      "I\n",
      "NLL: 0.3398 +/- 0.0177\n",
      "ECE: 0.0170 +/- 0.0099\n",
      "Acc: 0.9132 +/- 0.0017\n"
     ]
    }
   ],
   "source": [
    "# 1 models\n",
    "all_eq_f = [eq69_out_f, eq24_out_f, eq31_out_f, eq42_out_f]\n",
    "all_base_f = [b69_out_f, b24_out_f, b31_out_f]\n",
    "all_inv_f = [inv69_out_f, inv24_out_f, inv31_out_f]\n",
    "\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_E=1)\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_B=1)\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_I=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dying-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE\n",
      "NLL: 0.3326 +/- 0.0367\n",
      "ECE: 0.0216 +/- 0.0078\n",
      "Acc: 0.9225 +/- 0.0043\n",
      "EI\n",
      "NLL: 0.2829 +/- 0.0084\n",
      "ECE: 0.0149 +/- 0.0024\n",
      "Acc: 0.9276 +/- 0.0012\n",
      "EEE\n",
      "NLL: 0.3072 +/- 0.0277\n",
      "ECE: 0.0151 +/- 0.0064\n",
      "Acc: 0.9236 +/- 0.0023\n",
      "EEI\n",
      "NLL: 0.2778 +/- 0.0146\n",
      "ECE: 0.0132 +/- 0.0040\n",
      "Acc: 0.9295 +/- 0.0038\n"
     ]
    }
   ],
   "source": [
    "# 2 models\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_E=2)\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_E=1, num_I=1)\n",
    "\n",
    "# 3 models\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_E=3)\n",
    "ensem_BEI(all_eq_f, all_base_f, all_inv_f,tar_f,num_E=2, num_I=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_tar = b69_tar\n",
    "num_comb = 1\n",
    "all_eq_exR = [eq24_out, eq69_out, eq31_out]\n",
    "all_base_exR = [b24_out, b69_out, b31_out]\n",
    "all_inv_exR = [inv24_out, inv69_out, inv31_out]\n",
    "for i in range(num_comb):\n",
    "    [eq1] = np.random.choice(all_eq_exR, 1)\n",
    "    [b1] = np.random.choice(all_base_exR, 1)\n",
    "    [inv1] = np.random.choice(all_inv_exR, 1) \n",
    "    _,_,_,acc_pc_b = get_metrics([b1], [same_tar],['base'], num_classes=num_classes)\n",
    "    _,_,_,acc_pc_eq = get_metrics([eq1], [same_tar],['eq'], num_classes=num_classes)\n",
    "    _,_,_,acc_pc_inv = get_metrics([inv1], [same_tar],['inv'], num_classes=num_classes)\n",
    "    get_classwise(acc_pc_b, acc_pc_inv, acc_pc_eq, num_classes=num_classes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "floral-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded trans_cifar100_base69_cos_lr0.2_bs256\n",
      "b69\n",
      "NLL: 0.7387407422065735 | ECE: 0.0890038620114327\n",
      "Acc: 0.8535999655723572\n",
      "loaded trans_cifar100_eq69_cos_lr0.2_bs256\n",
      "eq69\n",
      "NLL: 0.7336560487747192 | ECE: 0.09125010451376434\n",
      "Acc: 0.8532999753952026\n",
      "loaded trans_cifar100_inv69_cos_lr0.2_bs256\n",
      "inv69\n",
      "NLL: 0.8228658437728882 | ECE: 0.10278177570402622\n",
      "Acc: 0.8385999798774719\n",
      "loaded trans_cifar100_base24_cos_lr0.2_bs256\n",
      "b24\n",
      "NLL: 0.7335842847824097 | ECE: 0.08970591485351326\n",
      "Acc: 0.8545999526977539\n",
      "loaded trans_cifar100_eq24_cos_lr0.2_bs256\n",
      "eq24\n",
      "NLL: 0.7076037526130676 | ECE: 0.08781001860648402\n",
      "Acc: 0.8554999828338623\n",
      "loaded trans_cifar100_inv24_cos_lr0.2_bs256\n",
      "inv24\n",
      "NLL: 0.8170745372772217 | ECE: 0.10017117341011764\n",
      "Acc: 0.8402000069618225\n",
      "loaded trans_cifar100_base31_cos_lr0.2_bs256\n",
      "b31\n",
      "NLL: 0.7173638939857483 | ECE: 0.08865366537570948\n",
      "Acc: 0.8531000018119812\n",
      "loaded trans_cifar100_eq31_cos_lr0.2_bs256\n",
      "eq31\n",
      "NLL: 0.6678038835525513 | ECE: 0.08116961831152442\n",
      "Acc: 0.85589998960495\n",
      "loaded trans_cifar100_inv31_cos_lr0.2_bs256\n",
      "inv31\n",
      "NLL: 0.8248342871665955 | ECE: 0.10126517752557994\n",
      "Acc: 0.8409000039100647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8248342871665955,\n",
       " 0.10126517752557994,\n",
       " 0.8409000039100647,\n",
       " tensor([0.9700, 0.9300, 0.7700, 0.7500, 0.7800, 0.8000, 0.9400, 0.8300, 0.9100,\n",
       "         0.9000, 0.7600, 0.6300, 0.9100, 0.7300, 0.8800, 0.8700, 0.8800, 0.8300,\n",
       "         0.8400, 0.8200, 0.8900, 0.9400, 0.9100, 0.9000, 0.9200, 0.8000, 0.8200,\n",
       "         0.8300, 0.7800, 0.8700, 0.7600, 0.8200, 0.8000, 0.8000, 0.8300, 0.5700,\n",
       "         0.9000, 0.8400, 0.8200, 0.9500, 0.8400, 0.9400, 0.8400, 0.8900, 0.8000,\n",
       "         0.7400, 0.7000, 0.6900, 0.9700, 0.9200, 0.7100, 0.8500, 0.7100, 0.9900,\n",
       "         0.9000, 0.7000, 0.9400, 0.9000, 0.9400, 0.6800, 0.9100, 0.8400, 0.8700,\n",
       "         0.7900, 0.6400, 0.7400, 0.9100, 0.8300, 0.9700, 0.9100, 0.8700, 0.8900,\n",
       "         0.7100, 0.8100, 0.7200, 0.9600, 0.9500, 0.8100, 0.8000, 0.9200, 0.8200,\n",
       "         0.8500, 0.9600, 0.8100, 0.8400, 0.9100, 0.8700, 0.9400, 0.8700, 0.9500,\n",
       "         0.9200, 0.8900, 0.8000, 0.7400, 0.9800, 0.8200, 0.7200, 0.8700, 0.7000,\n",
       "         0.8500], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR-100\n",
    "dataset_name = 'cifar100'\n",
    "num_classes = 100\n",
    "lr = '0.2'\n",
    "loader = c100_loader\n",
    "\n",
    "b69 = load_1_model(f\"trans_{dataset_name}_base69_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "b69_out, b69_tar = rollout_loader(b69, loader)\n",
    "same_tar = b69_tar\n",
    "get_metrics([b69_out], [same_tar],['b69'], num_classes=num_classes)\n",
    "eq69 = load_1_model(f\"trans_{dataset_name}_eq69_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "eq69_out, eq69_tar = rollout_loader(eq69, loader)\n",
    "get_metrics([eq69_out], [same_tar],['eq69'], num_classes=num_classes)\n",
    "\n",
    "inv69 = load_1_model(f\"trans_{dataset_name}_inv69_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "inv69_out, inv69_tar = rollout_loader(inv69, loader)\n",
    "get_metrics([inv69_out], [same_tar],['inv69'], num_classes=num_classes)\n",
    "\n",
    "assert(torch.equal(b69_tar,eq69_tar))\n",
    "\n",
    "b24 = load_1_model(f\"trans_{dataset_name}_base24_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "b24_out, _ = rollout_loader(b24, loader)\n",
    "get_metrics([b24_out], [same_tar],['b24'], num_classes=num_classes)\n",
    "\n",
    "eq24 = load_1_model(f\"trans_{dataset_name}_eq24_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "eq24_out, _ = rollout_loader(eq24, loader)\n",
    "get_metrics([eq24_out], [same_tar],['eq24'], num_classes=num_classes)\n",
    "\n",
    "inv24 = load_1_model(f\"trans_{dataset_name}_inv24_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "inv24_out, _ = rollout_loader(inv24, loader)\n",
    "get_metrics([inv24_out], [same_tar],['inv24'], num_classes=num_classes)\n",
    "\n",
    "\n",
    "b31 = load_1_model(f\"trans_{dataset_name}_base31_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "b31_out, _ = rollout_loader(b31, loader)\n",
    "get_metrics([b31_out], [same_tar],['b31'], num_classes=num_classes)\n",
    "\n",
    "eq31 = load_1_model(f\"trans_{dataset_name}_eq31_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "eq31_out, _ = rollout_loader(eq31, loader)\n",
    "get_metrics([eq31_out], [same_tar],['eq31'], num_classes=num_classes)\n",
    "\n",
    "inv31 = load_1_model(f\"trans_{dataset_name}_inv31_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "inv31_out, _ = rollout_loader(inv31, loader)\n",
    "get_metrics([inv31_out], [same_tar],['inv31'], num_classes=num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "political-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded trans_cifar100_eq42_cos_lr0.2_bs256\n",
      "eq42\n",
      "NLL: 0.6688125729560852 | ECE: 0.08455638369619847\n",
      "Acc: 0.858299970626831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6688125729560852,\n",
       " 0.08455638369619847,\n",
       " 0.858299970626831,\n",
       " tensor([0.9400, 0.9400, 0.7500, 0.7800, 0.7400, 0.8300, 0.9300, 0.8600, 0.9500,\n",
       "         0.9200, 0.7500, 0.6600, 0.8900, 0.8300, 0.8900, 0.9200, 0.8900, 0.9200,\n",
       "         0.8700, 0.8800, 0.9100, 0.9400, 0.9300, 0.9500, 0.9000, 0.8400, 0.7800,\n",
       "         0.8400, 0.8700, 0.8900, 0.8600, 0.8500, 0.8000, 0.8000, 0.8900, 0.6500,\n",
       "         0.9100, 0.9100, 0.8500, 0.9500, 0.8800, 0.9200, 0.8500, 0.9000, 0.8300,\n",
       "         0.8000, 0.7000, 0.7100, 0.9800, 0.9300, 0.7400, 0.9500, 0.6800, 0.9900,\n",
       "         0.9100, 0.7600, 0.9300, 0.9000, 0.9700, 0.7200, 0.8900, 0.7900, 0.8600,\n",
       "         0.7800, 0.6900, 0.8300, 0.9000, 0.7900, 0.9700, 0.9200, 0.8800, 0.9100,\n",
       "         0.6900, 0.8200, 0.7200, 0.9500, 0.9600, 0.8500, 0.8500, 0.9100, 0.8300,\n",
       "         0.8700, 0.9700, 0.8700, 0.8300, 0.9500, 0.8400, 0.9500, 0.8400, 0.9400,\n",
       "         0.9100, 0.9300, 0.7400, 0.8400, 0.9800, 0.8300, 0.7300, 0.9000, 0.7300,\n",
       "         0.8800], device='cuda:0'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'cifar100'\n",
    "num_classes = 100\n",
    "lr = '0.2'\n",
    "loader = c100_loader\n",
    "\n",
    "eq42 = load_1_model(f\"trans_{dataset_name}_eq42_cos_lr{lr}_bs256\", num_classes=num_classes)\n",
    "eq42_out, eq42_tar = rollout_loader(eq42, loader)\n",
    "get_metrics([eq42_out], [eq42_tar],['eq42'], num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "divided-somerset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "NLL: 0.6943 +/- 0.0321\n",
      "ECE: 0.0859 +/- 0.0046\n",
      "Acc: 0.8553 +/- 0.0019\n",
      "B\n",
      "NLL: 0.7174 +/- 0.0000\n",
      "ECE: 0.0887 +/- 0.0000\n",
      "Acc: 0.8531 +/- 0.0000\n",
      "I\n",
      "NLL: 0.8229 +/- 0.0030\n",
      "ECE: 0.1013 +/- 0.0008\n",
      "Acc: 0.8403 +/- 0.0009\n",
      "EE\n",
      "NLL: 0.5501 +/- 0.0086\n",
      "ECE: 0.0489 +/- 0.0023\n",
      "Acc: 0.8674 +/- 0.0023\n",
      "EI\n",
      "NLL: 0.5687 +/- 0.0093\n",
      "ECE: 0.0446 +/- 0.0017\n",
      "Acc: 0.8654 +/- 0.0011\n",
      "EEE\n",
      "NLL: 0.5104 +/- 0.0068\n",
      "ECE: 0.0403 +/- 0.0025\n",
      "Acc: 0.8705 +/- 0.0013\n",
      "EEI\n",
      "NLL: 0.5145 +/- 0.0026\n",
      "ECE: 0.0342 +/- 0.0017\n",
      "Acc: 0.8703 +/- 0.0013\n"
     ]
    }
   ],
   "source": [
    "same_tar = eq42_tar\n",
    "all_eq = [eq69_out, eq24_out, eq31_out, eq42_out]\n",
    "all_base = [b69_out, b24_out, b31_out]\n",
    "all_inv = [inv69_out, inv24_out, inv31_out]\n",
    "\n",
    "# 1 models\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar, num_E=1)\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar,num_B=1)\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar,num_I=1)\n",
    "\n",
    "# 2 models\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar,num_E=2)\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar,num_E=1, num_I=1)\n",
    "\n",
    "# 3 models\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar,num_E=3)\n",
    "ensem_BEI(all_eq, all_base, all_inv, same_tar,num_E=2, num_I=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "clinical-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.55000000000001"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(91.2+91.9)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "growing-dover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.66666666666667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(91.2+91.9+91.9)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "monetary-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.030000000000001"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87.03-(85.5+84.0+85.5)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "twelve-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7900000000000063"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "86.54-(85.5+84.0)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dangerous-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "NLL: 0.7335842847824097 | ECE: 0.08970591485351326\n",
      "Acc: 0.8545999526977539\n",
      "eq\n",
      "NLL: 0.6688125729560852 | ECE: 0.08455638369619847\n",
      "Acc: 0.858299970626831\n",
      "inv\n",
      "NLL: 0.8228658437728882 | ECE: 0.10278177570402622\n",
      "Acc: 0.8385999798774719\n",
      "use order B, I, E\n",
      "all equal best: 5.0%\n",
      "B,I equal best: 2.0%\n",
      "B,E equal best: 5.0%\n",
      "I,E equal best: 5.0%\n",
      "B uniquely best: 33.0%\n",
      "I uniquely best: 13.0%\n",
      "E uniquely best: 37.0%\n"
     ]
    }
   ],
   "source": [
    "b1 = b24_out\n",
    "eq1 = eq42_out\n",
    "inv1 = inv69_out\n",
    "\n",
    "_,_,_,acc_pc_b = get_metrics([b1], [same_tar],['base'], num_classes=num_classes)\n",
    "_,_,_,acc_pc_eq = get_metrics([eq1], [same_tar],['eq'], num_classes=num_classes)\n",
    "_,_,_,acc_pc_inv = get_metrics([inv1], [same_tar],['inv'], num_classes=num_classes)\n",
    "get_classwise(acc_pc_b, acc_pc_inv, acc_pc_eq, num_classes=num_classes)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "willing-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "NLL: 0.7387407422065735 | ECE: 0.0890038620114327\n",
      "Acc: 0.8535999655723572\n",
      "eq\n",
      "NLL: 0.7336560487747192 | ECE: 0.09125010451376434\n",
      "Acc: 0.8532999753952026\n",
      "inv\n",
      "NLL: 0.8170745372772217 | ECE: 0.10017117341011764\n",
      "Acc: 0.8402000069618225\n",
      "use order B, I, E\n",
      "all equal best: 1.0%\n",
      "B,I equal best: 0.0%\n",
      "B,E equal best: 13.0%\n",
      "I,E equal best: 8.0%\n",
      "B uniquely best: 33.0%\n",
      "I uniquely best: 21.0%\n",
      "E uniquely best: 24.0%\n"
     ]
    }
   ],
   "source": [
    "same_tar = b69_tar\n",
    "num_comb = 1\n",
    "all_eq_exR = [eq24_out, eq69_out, eq31_out]\n",
    "all_base_exR = [b24_out, b69_out, b31_out]\n",
    "all_inv_exR = [inv24_out, inv69_out, inv31_out]\n",
    "for i in range(num_comb):\n",
    "    [eq1] = np.random.choice(all_eq_exR, 1)\n",
    "    [b1] = np.random.choice(all_base_exR, 1)\n",
    "    [inv1] = np.random.choice(all_inv_exR, 1) \n",
    "    _,_,_,acc_pc_b = get_metrics([b1], [same_tar],['base'], num_classes=num_classes)\n",
    "    _,_,_,acc_pc_eq = get_metrics([eq1], [same_tar],['eq'], num_classes=num_classes)\n",
    "    _,_,_,acc_pc_inv = get_metrics([inv1], [same_tar],['inv'], num_classes=num_classes)\n",
    "    get_classwise(acc_pc_b, acc_pc_inv, acc_pc_eq, num_classes=num_classes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dated-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEE_comb0\n",
      "NLL: 0.5832626223564148 | ECE: 0.06168382893055683\n",
      "Acc: 0.8614999651908875\n",
      "Diversity agree: 0.9251333475112915 | disagree: 0.07486666738986969\n",
      "BBB_comb0\n",
      "NLL: 0.5279425978660583 | ECE: 0.04105125807672736\n",
      "Acc: 0.8693000078201294\n",
      "Diversity agree: 0.882099986076355 | disagree: 0.11789999902248383\n",
      "III_comb0\n",
      "NLL: 0.5802863240242004 | ECE: 0.043603131787478946\n",
      "Acc: 0.8579999804496765\n",
      "Diversity agree: 0.8637666702270508 | disagree: 0.13623332977294922\n",
      "BEI_comb0\n",
      "NLL: 0.521447479724884 | ECE: 0.03460804491192103\n",
      "Acc: 0.8698999881744385\n",
      "Diversity agree: 0.8691666722297668 | disagree: 0.13083332777023315\n",
      "\n",
      "EEE Acc: 0.8614999651908875 +/- 0.0\n",
      "EEE ECE: 0.06168382893055683 +/- 0.0\n",
      "EEE NLL: 0.5832626223564148 +/- 0.0\n",
      "\n",
      "BBB Acc: 0.8693000078201294 +/- 0.0\n",
      "BBB ECE: 0.04105125807672736 +/- 0.0\n",
      "BBB NLL: 0.5279425978660583 +/- 0.0\n",
      "\n",
      "III Acc: 0.8579999804496765 +/- 0.0\n",
      "III ECE: 0.043603131787478946 +/- 0.0\n",
      "III NLL: 0.5802863240242004 +/- 0.0\n",
      "\n",
      "BEI Acc: 0.8698999881744385 +/- 0.0\n",
      "BEI ECE: 0.03460804491192103 +/- 0.0\n",
      "BEI NLL: 0.521447479724884 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "num_comb =1 \n",
    "eee_nll = []\n",
    "eee_ece = []\n",
    "eee_acc = []\n",
    "for i in range(num_comb):\n",
    "    [eq1, eq2, eq3] = np.random.choice(all_eq_exR, 3, replace=False)\n",
    "    eee_out = (eq1.softmax(-1) + eq2.softmax(-1) + eq3.softmax(-1))/3\n",
    "    nll, ece, acc, _ = get_metrics([eee_out],[same_tar],[f'EEE_comb{i}'], input_softmax=True, num_classes=num_classes)    \n",
    "    ag, dag, kld, std_logits, std = get_div_metrics(eq1,eq2,eq3, same_tar)\n",
    "\n",
    "    eee_nll.append(nll)\n",
    "    eee_ece.append(ece)  \n",
    "    eee_acc.append(acc)   \n",
    "\n",
    "bbb_nll = []\n",
    "bbb_ece = []\n",
    "bbb_acc = []\n",
    "for i in range(num_comb):\n",
    "    [b1, b2, b3] = np.random.choice(all_base_exR, 3, replace=False)\n",
    "    bbb_out = (b1.softmax(-1) + b2.softmax(-1) + b3.softmax(-1))/3\n",
    "    nll, ece, acc, _ = get_metrics([bbb_out],[same_tar],[f'BBB_comb{i}'], input_softmax=True, num_classes=num_classes)      \n",
    "    ag, dag, kld, std_logits, std = get_div_metrics(b1,b2,b3, same_tar)\n",
    "\n",
    "    bbb_nll.append(nll)\n",
    "    bbb_ece.append(ece)  \n",
    "    bbb_acc.append(acc) \n",
    "\n",
    "iii_nll = []\n",
    "iii_ece = []\n",
    "iii_acc = []\n",
    "for i in range(num_comb):\n",
    "    [i1, i2, i3] = np.random.choice(all_inv_exR, 3, replace=False)\n",
    "    iii_out = (i1.softmax(-1) + i2.softmax(-1) + i3.softmax(-1))/3\n",
    "    nll, ece, acc, _ = get_metrics([iii_out],[same_tar],[f'III_comb{i}'], input_softmax=True, num_classes=num_classes)      \n",
    "    ag, dag, kld, std_logits, std = get_div_metrics(i1,i2,i3, same_tar)\n",
    "    \n",
    "    iii_nll.append(nll)\n",
    "    iii_ece.append(ece)  \n",
    "    iii_acc.append(acc) \n",
    "    \n",
    "bei_nll = []\n",
    "bei_ece = []\n",
    "bei_acc = []\n",
    "for i in range(num_comb):\n",
    "#     [eq1] = np.random.choice(all_eq_exR, 1)\n",
    "#     [base1] = np.random.choice(all_base_exR, 1)\n",
    "#     [inv1] = np.random.choice(all_inv_exR, 1)\n",
    "    [eq1] = np.random.choice([eq31_out], 1)\n",
    "    [base1] = np.random.choice([b31_out], 1)\n",
    "    [inv1] = np.random.choice([inv24_out], 1)\n",
    "    bei_out = (eq1.softmax(-1) + base1.softmax(-1) + inv1.softmax(-1))/3\n",
    "    \n",
    "    nll, ece, acc, _ = get_metrics([bei_out],[same_tar],[f'BEI_comb{i}'], input_softmax=True, num_classes=num_classes)     \n",
    "    ag, dag, kld, std_logits, std = get_div_metrics(eq1,base1,inv1, same_tar)\n",
    "    \n",
    "    bei_nll.append(nll)\n",
    "    bei_ece.append(ece)  \n",
    "    bei_acc.append(acc) \n",
    "\n",
    "print(f\"\\nEEE Acc: {np.mean(eee_acc)} +/- {np.std(eee_acc)}\")\n",
    "print(f\"EEE ECE: {np.mean(eee_ece)} +/- {np.std(eee_ece)}\")\n",
    "print(f\"EEE NLL: {np.mean(eee_nll)} +/- {np.std(eee_nll)}\")\n",
    "\n",
    "print(f\"\\nBBB Acc: {np.mean(bbb_acc)} +/- {np.std(bbb_acc)}\")\n",
    "print(f\"BBB ECE: {np.mean(bbb_ece)} +/- {np.std(bbb_ece)}\")\n",
    "print(f\"BBB NLL: {np.mean(bbb_nll)} +/- {np.std(bbb_nll)}\")\n",
    "\n",
    "print(f\"\\nIII Acc: {np.mean(iii_acc)} +/- {np.std(iii_acc)}\")\n",
    "print(f\"III ECE: {np.mean(iii_ece)} +/- {np.std(iii_ece)}\")\n",
    "print(f\"III NLL: {np.mean(iii_nll)} +/- {np.std(iii_nll)}\")\n",
    "\n",
    "print(f\"\\nBEI Acc: {np.mean(bei_acc)} +/- {np.std(bei_acc)}\")\n",
    "print(f\"BEI ECE: {np.mean(bei_ece)} +/- {np.std(bei_ece)}\")\n",
    "print(f\"BEI NLL: {np.mean(bei_nll)} +/- {np.std(bei_nll)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "suited-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agree: 0.9224806427955627 | disagree: 0.07751938700675964\n",
      "Ensemble Variance Logits: 1.2094038724899292\n",
      "Ensemble Variance: 0.0014868759317323565\n",
      "KL div: 0.22746145725250244\n"
     ]
    }
   ],
   "source": [
    "ag, dag, kld, std_logits, std = get_div_metrics(b24_out,eq24_out,inv24_out, same_tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ultimate-burner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agree: 0.9501274228096008 | disagree: 0.049872610718011856\n",
      "Ensemble Variance Logits: 0.9655865430831909\n",
      "Ensemble Variance: 0.0009998121531680226\n",
      "KL div: 0.15915538370609283\n"
     ]
    }
   ],
   "source": [
    "ag, dag, kld, std_logits, std = get_div_metrics(eq69_out,eq24_out,eq31_out, same_tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fossil-bargain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agree: 0.9201496243476868 | disagree: 0.07985038310289383\n",
      "Ensemble Variance Logits: 1.0752143859863281\n",
      "Ensemble Variance: 0.0014482238329946995\n",
      "KL div: 0.21660903096199036\n"
     ]
    }
   ],
   "source": [
    "ag, dag, kld, std_logits, std = get_div_metrics(inv69_out,inv24_out,inv31_out, same_tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "genuine-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agree: 0.9288774132728577 | disagree: 0.0711226761341095\n",
      "Ensemble Variance Logits: 1.0374211072921753\n",
      "Ensemble Variance: 0.0013705750461667776\n",
      "KL div: 0.19209891557693481\n"
     ]
    }
   ],
   "source": [
    "ag, dag, kld, std_logits, std = get_div_metrics(b69_out,b24_out,b31_out, same_tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-tunisia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
